window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = [{"fullname": "nlp_uncertainty_zoo.models.__init__", "modulename": "nlp_uncertainty_zoo.models.__init__", "type": "module", "doc": "<p></p>\n"}, {"fullname": "nlp_uncertainty_zoo.models.bayesian_lstm", "modulename": "nlp_uncertainty_zoo.models.bayesian_lstm", "type": "module", "doc": "<p>Implement the Bayesian Bayes-by-backprop LSTM by <a href=\"https://arxiv.org/pdf/1704.02798.pdf\">Fortunato et al. (2017) </a>.</p>\n"}, {"fullname": "nlp_uncertainty_zoo.models.bayesian_lstm.BayesianLSTMModule", "modulename": "nlp_uncertainty_zoo.models.bayesian_lstm", "qualname": "BayesianLSTMModule", "type": "class", "doc": "<p>Implementation of a Bayes-by-backprop LSTM by Fortunato et al. (2017).</p>\n", "bases": "nlp_uncertainty_zoo.models.lstm.LSTMModule, nlp_uncertainty_zoo.models.model.MultiPredictionMixin"}, {"fullname": "nlp_uncertainty_zoo.models.bayesian_lstm.BayesianLSTMModule.__init__", "modulename": "nlp_uncertainty_zoo.models.bayesian_lstm", "qualname": "BayesianLSTMModule.__init__", "type": "function", "doc": "<p>Initialize a Bayesian LSTM.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>num_layers</strong> (int):\nNumber of layers.</li>\n<li><strong>vocab_size</strong> (int):\nNumber of input vocabulary.</li>\n<li><strong>input_size</strong> (int):\nDimensionality of input to the first layer (embedding size).</li>\n<li><strong>hidden_size</strong> (int):\nSize of hidden units.</li>\n<li><strong>output_size</strong> (int):\nNumber of classes.</li>\n<li><strong>dropout</strong> (float):\nDropout probability.</li>\n<li><strong>posterior_rho_init</strong> (float):\nPosterior mean for the weight rho init.</li>\n<li><strong>posterior_mu_init</strong> (float):\nPosterior mean for the weight mu init.</li>\n<li><strong>prior_pi</strong> (float):\nMixture weight of the prior.</li>\n<li><strong>prior_sigma_1</strong> (float):\nPrior sigma on the mixture prior distribution 1.</li>\n<li><strong>prior_sigma_2</strong> (float):\nPrior sigma on the mixture prior distribution 2.</li>\n<li><strong>num_predictions</strong> (int):\nNumber of predictions (forward passes) used to make predictions.</li>\n<li><strong>is_sequence_classifier</strong> (bool):\nIndicate whether model is going to be used as a sequence classifier. Otherwise, predictions are going to\nmade at every time step.</li>\n<li><strong>device</strong> (Device):\nDevice the model should be moved to.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">num_layers</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">vocab_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">input_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">hidden_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">output_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">dropout</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">prior_sigma_1</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">prior_sigma_2</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">prior_pi</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">posterior_mu_init</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">posterior_rho_init</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">num_predictions</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">is_sequence_classifier</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">build_params</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.bayesian_lstm.BayesianLSTMModule.get_logits", "modulename": "nlp_uncertainty_zoo.models.bayesian_lstm", "qualname": "BayesianLSTMModule.get_logits", "type": "function", "doc": "<p>Get the logits for an input. Results in a tensor of size batch_size x seq_len x output_size or batch_size x\nnum_predictions x seq_len x output_size depending on the model type. Used to create inputs for the uncertainty\nmetrics defined in nlp_uncertainty_zoo.metrics.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\n(Batch of) Indexed input sequences.</li>\n<li><strong>num_predictions</strong> (Optional[int]):\nNumber of predictions (forward passes) used to make predictions.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Logits for current input.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>,</span><span class=\"param\">\t<span class=\"o\">*</span><span class=\"n\">args</span>,</span><span class=\"param\">\t<span class=\"n\">num_predictions</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.bayesian_lstm.BayesianLSTMModule.predict", "modulename": "nlp_uncertainty_zoo.models.bayesian_lstm", "qualname": "BayesianLSTMModule.predict", "type": "function", "doc": "<p>Output a probability distribution over classes given an input. Results in a tensor of size batch_size x seq_len\nx output_size or batch_size x num_predictions x seq_len x output_size depending on the model type.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\n(Batch of) Indexed input sequences.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Logits for current input.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.bayesian_lstm.BayesianLSTM", "modulename": "nlp_uncertainty_zoo.models.bayesian_lstm", "qualname": "BayesianLSTM", "type": "class", "doc": "<p>Abstract model class. It is a wrapper that defines data loading, batching, training and evaluation loops, so that\nthe core module class can only define the model's forward pass.</p>\n", "bases": "nlp_uncertainty_zoo.models.model.Model"}, {"fullname": "nlp_uncertainty_zoo.models.bayesian_lstm.BayesianLSTM.__init__", "modulename": "nlp_uncertainty_zoo.models.bayesian_lstm", "qualname": "BayesianLSTM.__init__", "type": "function", "doc": "<p>Initialize a module.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>model_name</strong> (str):\nName of the model.</li>\n<li><strong>module_class</strong> (type):\nClass of the model that is being wrapped.</li>\n<li><strong>model_params</strong> (Dict[str, Any]):\nParameters to initialize the model.</li>\n<li><strong>device</strong> (Device):\nThe device the model is located on.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model_params</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">model_dir</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;cpu&#39;</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.bert", "modulename": "nlp_uncertainty_zoo.models.bert", "type": "module", "doc": "<p>Define BERT modules used in this project and make them consistent with the other models in the repository.</p>\n"}, {"fullname": "nlp_uncertainty_zoo.models.bert.BertModule", "modulename": "nlp_uncertainty_zoo.models.bert", "qualname": "BertModule", "type": "class", "doc": "<p>Define a BERT module that implements all the functions implemented in Module.</p>\n", "bases": "nlp_uncertainty_zoo.models.model.Module"}, {"fullname": "nlp_uncertainty_zoo.models.bert.BertModule.__init__", "modulename": "nlp_uncertainty_zoo.models.bert", "qualname": "BertModule.__init__", "type": "function", "doc": "<p>Initialize a BERT module.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>bert_name</strong> (str):\nName of the underlying BERT, as specified in HuggingFace transformers.</li>\n<li><strong>output_size</strong> (int):\nNumber of classes.</li>\n<li><strong>is_sequence_classifier</strong> (bool):\nIndicate whether model is going to be used as a sequence classifier. Otherwise, predictions are going to\nmade at every time step.</li>\n<li><strong>device</strong> (Device):\nDevice the model should be moved to.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">bert_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">output_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">is_sequence_classifier</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">build_params</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.bert.BertModule.forward", "modulename": "nlp_uncertainty_zoo.models.bert", "qualname": "BertModule.forward", "type": "function", "doc": "<p>Forward pass of the model.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\n(Batch of) Indexed input sequences.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Output predictions for input.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.bert.BertModule.get_logits", "modulename": "nlp_uncertainty_zoo.models.bert", "qualname": "BertModule.get_logits", "type": "function", "doc": "<p>Get the logits for an input. Results in a tensor of size batch_size x seq_len x output_size or batch_size x\nnum_predictions x seq_len x output_size depending on the model type. Used to create inputs for the uncertainty\nmetrics defined in nlp_uncertainty_zoo.metrics.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\n(Batch of) Indexed input sequences.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Logits for current input.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.bert.BertModule.predict", "modulename": "nlp_uncertainty_zoo.models.bert", "qualname": "BertModule.predict", "type": "function", "doc": "<p>Output a probability distribution over classes given an input. Results in a tensor of size batch_size x seq_len\nx output_size or batch_size x num_predictions x seq_len x output_size depending on the model type.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\n(Batch of) Indexed input sequences.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Logits for current input.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.bert.BertModule.get_sequence_representation", "modulename": "nlp_uncertainty_zoo.models.bert", "qualname": "BertModule.get_sequence_representation", "type": "function", "doc": "<p>Define how the representation for an entire sequence is extracted from a number of hidden states. This is\nrelevant in sequence classification. For example, this could be the last hidden state for a unidirectional LSTM\nor the first hidden state for a transformer, adding a pooler layer.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>hidden</strong> (torch.FloatTensor):\nHidden states of a model for a sequence.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Representation for the current sequence.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">hidden</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.bert.BertModule.get_hidden", "modulename": "nlp_uncertainty_zoo.models.bert", "qualname": "BertModule.get_hidden", "type": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.ddu_transformer", "modulename": "nlp_uncertainty_zoo.models.ddu_transformer", "type": "module", "doc": "<p>Implementation of the Deep Deterministic Uncertainty (DDU) Transformer by\n <a href=\"https://arxiv.org/pdf/2102.11582.pdf\">Mukhoti et al. (2021) </a>.</p>\n"}, {"fullname": "nlp_uncertainty_zoo.models.ddu_transformer.DDUMixin", "modulename": "nlp_uncertainty_zoo.models.ddu_transformer", "qualname": "DDUMixin", "type": "class", "doc": "<p>Implementation of the functions used by the Deep Deterministic Uncertainty (DDU) Transformer by\n<a href=\"https://arxiv.org/pdf/2102.11582.pdf\">Mukhoti et al. (2021) </a>. as a Mixin class. This is done to avoid code\nredundancies.</p>\n"}, {"fullname": "nlp_uncertainty_zoo.models.ddu_transformer.DDUMixin.__init__", "modulename": "nlp_uncertainty_zoo.models.ddu_transformer", "qualname": "DDUMixin.__init__", "type": "function", "doc": "<p>Initialize a DDUMixin.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_size</strong> (int):\nDimensionality of input to the Gaussian Mixture Model layer.</li>\n<li><strong>output_size</strong> (int):\nNumber of classes.</li>\n<li><strong>ignore_indices</strong> (List[int]):\nList of indices for which activations should be ignored when fitting the GMM.</li>\n<li><strong>projection_size</strong> (Optional[int]):\nIf given, project hidden activations into a subspace with dimensionality projection_size. Default is None.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">input_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">output_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">ignore_indices</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">projection_size</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.ddu_transformer.DDUMixin.gmm_fit", "modulename": "nlp_uncertainty_zoo.models.ddu_transformer", "qualname": "DDUMixin.gmm_fit", "type": "function", "doc": "<p>Fit a Gaussian mixture model on the feature representations of the trained model.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>data_split</strong> (DataSplit):\nData split used for fitting, usually the training or validation split.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">data_split</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataloader</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.ddu_transformer.DDUMixin.gmm_predict", "modulename": "nlp_uncertainty_zoo.models.ddu_transformer", "qualname": "DDUMixin.gmm_predict", "type": "function", "doc": "<p>Make a prediction with the Gaussian mixture Model for a batch of inputs.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\nBatch of inputs in the form of indexed tokens.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Probability of the input under every mixture component, with one component per class.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.ddu_transformer.DDUTransformerModule", "modulename": "nlp_uncertainty_zoo.models.ddu_transformer", "qualname": "DDUTransformerModule", "type": "class", "doc": "<p>Implementation of the Deep Deterministic Uncertainty (DDU) Transformer by\n<a href=\"https://arxiv.org/pdf/2102.11582.pdf\">Mukhoti et al. (2021) </a>.</p>\n", "bases": "nlp_uncertainty_zoo.models.spectral.SpectralTransformerModule, DDUMixin"}, {"fullname": "nlp_uncertainty_zoo.models.ddu_transformer.DDUTransformerModule.__init__", "modulename": "nlp_uncertainty_zoo.models.ddu_transformer", "qualname": "DDUTransformerModule.__init__", "type": "function", "doc": "<p>Initialize a DDU transformer.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>num_layers</strong> (int):\nNumber of model layers.</li>\n<li><strong>vocab_size</strong> (int):\nVocabulary size.</li>\n<li><strong>input_size</strong> (int):\nDimensionality of input to model.</li>\n<li><strong>hidden_size</strong> (int):\nSize of hidden representations.</li>\n<li><strong>output_size</strong> (int):\nSize of output of model.</li>\n<li><strong>input_dropout</strong> (float):\nInput dropout added to embeddings.</li>\n<li><strong>dropout</strong> (float):\nDropout rate.</li>\n<li><strong>num_heads</strong> (int):\nNumber of self-attention heads per layer.</li>\n<li><strong>sequence_length</strong> (int):\nMaximum sequence length in dataset. Used to initialize positional embeddings.</li>\n<li><strong>projection_size</strong> (int):\nSize hidden dimensions are projected to using PCA to save memory if given.</li>\n<li><strong>is_sequence_classifier</strong> (bool):\nIndicate whether model is going to be used as a sequence classifier. Otherwise, predictions are going to\nmade at every time step.</li>\n<li><strong>ignore_indices</strong> (List[int]):\nToken indices to ignore when fitting the Gaussian Discriminant Analysis.</li>\n<li><strong>device</strong> (Device):\nDevice the model is located on.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">num_layers</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">vocab_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">input_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">hidden_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">output_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">input_dropout</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">dropout</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">num_heads</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">sequence_length</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">spectral_norm_upper_bound</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">projection_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">is_sequence_classifier</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">ignore_indices</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">build_params</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.ddu_transformer.DDUTransformer", "modulename": "nlp_uncertainty_zoo.models.ddu_transformer", "qualname": "DDUTransformer", "type": "class", "doc": "<p>Abstract model class. It is a wrapper that defines data loading, batching, training and evaluation loops, so that\nthe core module class can only define the model's forward pass.</p>\n", "bases": "nlp_uncertainty_zoo.models.model.Model"}, {"fullname": "nlp_uncertainty_zoo.models.ddu_transformer.DDUTransformer.__init__", "modulename": "nlp_uncertainty_zoo.models.ddu_transformer", "qualname": "DDUTransformer.__init__", "type": "function", "doc": "<p>Initialize a module.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>model_name</strong> (str):\nName of the model.</li>\n<li><strong>module_class</strong> (type):\nClass of the model that is being wrapped.</li>\n<li><strong>model_params</strong> (Dict[str, Any]):\nParameters to initialize the model.</li>\n<li><strong>device</strong> (Device):\nThe device the model is located on.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model_params</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">model_dir</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;cpu&#39;</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.ddu_transformer.DDUBertModule", "modulename": "nlp_uncertainty_zoo.models.ddu_transformer", "qualname": "DDUBertModule", "type": "class", "doc": "<p>Implementation of the Deep Deterministic Uncertainty (DDU) Transformer by\n<a href=\"https://arxiv.org/pdf/2102.11582.pdf\">Mukhoti et al. (2021) </a> in the form of a pre-trained BERT.</p>\n", "bases": "nlp_uncertainty_zoo.models.spectral.SpectralBertModule, DDUMixin"}, {"fullname": "nlp_uncertainty_zoo.models.ddu_transformer.DDUBertModule.__init__", "modulename": "nlp_uncertainty_zoo.models.ddu_transformer", "qualname": "DDUBertModule.__init__", "type": "function", "doc": "<p>Initialize a spectrally-normalized BERT.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>bert_name</strong> (str):\nName of the underlying BERT, as specified in HuggingFace transformers.</li>\n<li><strong>output_size</strong> (int):\nNumber of classes.</li>\n<li><strong>spectral_norm_upper_bound</strong> (float):\nSet a limit when weight matrices will be spectrally normalized if their eigenvalue surpasses it.</li>\n<li><strong>is_sequence_classifier</strong> (bool):\nIndicate whether model is going to be used as a sequence classifier. Otherwise, predictions are going to\nmade at every time step.</li>\n<li><strong>device</strong> (Device):\nDevice the model should be moved to.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">bert_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">output_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">spectral_norm_upper_bound</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">projection_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">is_sequence_classifier</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">ignore_indices</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">build_params</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.ddu_transformer.DDUBertModule.get_uncertainty", "modulename": "nlp_uncertainty_zoo.models.ddu_transformer", "qualname": "DDUBertModule.get_uncertainty", "type": "function", "doc": "<p>Get the uncertainty scores for the current batch.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\n(Batch of) Indexed input sequences.</li>\n<li><strong>metric_name</strong> (str):\nName of uncertainty metric being used.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Uncertainty scores for the current batch.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>,</span><span class=\"param\">\t<span class=\"o\">*</span><span class=\"n\">args</span>,</span><span class=\"param\">\t<span class=\"n\">metric_name</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.ddu_transformer.DDUBert", "modulename": "nlp_uncertainty_zoo.models.ddu_transformer", "qualname": "DDUBert", "type": "class", "doc": "<p>Abstract model class. It is a wrapper that defines data loading, batching, training and evaluation loops, so that\nthe core module class can only define the model's forward pass.</p>\n", "bases": "nlp_uncertainty_zoo.models.model.Model"}, {"fullname": "nlp_uncertainty_zoo.models.ddu_transformer.DDUBert.__init__", "modulename": "nlp_uncertainty_zoo.models.ddu_transformer", "qualname": "DDUBert.__init__", "type": "function", "doc": "<p>Initialize a module.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>model_name</strong> (str):\nName of the model.</li>\n<li><strong>module_class</strong> (type):\nClass of the model that is being wrapped.</li>\n<li><strong>model_params</strong> (Dict[str, Any]):\nParameters to initialize the model.</li>\n<li><strong>device</strong> (Device):\nThe device the model is located on.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model_params</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">model_dir</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;cpu&#39;</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.dpp_transformer", "modulename": "nlp_uncertainty_zoo.models.dpp_transformer", "type": "module", "doc": "<p>Implementing MC Dropout estimates using Determinantal Point Processes by\n<code>Shelmanov et al. (2021) &lt;https://aclanthology.org/2021.eacl-main.157.pdf&gt;_</code>. Code is a modified version of\n<code>their codebase &lt;https://github.com/skoltech-nlp/certain-transformer&gt;_</code>.</p>\n"}, {"fullname": "nlp_uncertainty_zoo.models.dpp_transformer.DropoutDPP", "modulename": "nlp_uncertainty_zoo.models.dpp_transformer", "qualname": "DropoutDPP", "type": "class", "doc": "<p>Implementation of the determinantal point process dropout, modified version of\n<code>the original implementation &lt;https://github.com/skoltech-nlp/certain-transformer/blob/main/src/ue4nlp/dropout_dpp.py&gt;_</code>.</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "nlp_uncertainty_zoo.models.dpp_transformer.DropoutDPP.__init__", "modulename": "nlp_uncertainty_zoo.models.dpp_transformer", "qualname": "DropoutDPP.__init__", "type": "function", "doc": "<p>Initialize a DPP dropout module.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>p</strong> (float):\nDropout probability.</li>\n<li><strong>max_n</strong> (int):\nMaximum number of iterations.</li>\n<li><strong>max_frac</strong> (float):\nMaximum fraction of dropped-out neurons.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">p</span><span class=\"p\">:</span> <span class=\"nb\">float</span>, </span><span class=\"param\"><span class=\"n\">max_n</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">100</span>, </span><span class=\"param\"><span class=\"n\">max_frac</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.4</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.dpp_transformer.DropoutDPP.update", "modulename": "nlp_uncertainty_zoo.models.dpp_transformer", "qualname": "DropoutDPP.update", "type": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">cls</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.dpp_transformer.DropoutDPP.forward", "modulename": "nlp_uncertainty_zoo.models.dpp_transformer", "qualname": "DropoutDPP.forward", "type": "function", "doc": "<p>Apply mask to the input. If model is in training mode, apply a normal dropout mask. If the model is in\ninference mode, apply DPP dropout.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>x</strong> (torch.Tensor):\nInput to which dropout mask is being applied to.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.Tensor</strong>: Input after applying dropout mask.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.dpp_transformer.DropoutDPP.get_mask", "modulename": "nlp_uncertainty_zoo.models.dpp_transformer", "qualname": "DropoutDPP.get_mask", "type": "function", "doc": "<p>Generate a new mask for a given input.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>x</strong> (torch.Tensor):\nInput for which the mask is supposed to be generated.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong></li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.dpp_transformer.DropoutDPP.calc_non_zero_neurons", "modulename": "nlp_uncertainty_zoo.models.dpp_transformer", "qualname": "DropoutDPP.calc_non_zero_neurons", "type": "function", "doc": "<p>Compute the fraction of neurons that have not been dropped out yet.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>sum_mask</strong> (torch.Tensor):\nCurrent mask.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>float</strong>: Percentage of non-dropped out neurons.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">sum_mask</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">float</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.dpp_transformer.DPPTransformerModule", "modulename": "nlp_uncertainty_zoo.models.dpp_transformer", "qualname": "DPPTransformerModule", "type": "class", "doc": "<p>Implementation of Variational Transformer by <a href=\"https://arxiv.org/pdf/2006.08344.pdf\">Xiao et al., (2021) </a>.</p>\n", "bases": "nlp_uncertainty_zoo.models.variational_transformer.VariationalTransformerModule"}, {"fullname": "nlp_uncertainty_zoo.models.dpp_transformer.DPPTransformerModule.__init__", "modulename": "nlp_uncertainty_zoo.models.dpp_transformer", "qualname": "DPPTransformerModule.__init__", "type": "function", "doc": "<p>Initialize a transformer.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>num_layers</strong> (int):\nNumber of model layers.</li>\n<li><strong>vocab_size</strong> (int):\nVocabulary size.</li>\n<li><strong>input_size</strong> (int):\nDimensionality of input to model.</li>\n<li><strong>hidden_size</strong> (int):\nSize of hidden representations.</li>\n<li><strong>output_size</strong> (int):\nSize of output of model.</li>\n<li><strong>input_dropout</strong> (float):\nDropout on word embeddings.</li>\n<li><strong>dropout</strong> (float):\nDropout rate.</li>\n<li><strong>num_heads</strong> (int):\nNumber of self-attention heads per layer.</li>\n<li><strong>sequence_length</strong> (int):\nMaximum sequence length in dataset. Used to initialize positional embeddings.</li>\n<li><strong>num_predictions</strong> (int):\nNumber of predictions with different dropout masks.</li>\n<li><strong>is_sequence_classifier</strong> (bool):\nIndicate whether model is going to be used as a sequence classifier. Otherwise, predictions are going to\nmade at every time step.</li>\n<li><strong>device</strong> (Device):\nDevice the model is located on.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">num_layers</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">vocab_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">input_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">hidden_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">output_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">input_dropout</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">dropout</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">num_heads</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">sequence_length</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_predictions</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">is_sequence_classifier</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">build_params</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.dpp_transformer.DPPTransformerModule.eval", "modulename": "nlp_uncertainty_zoo.models.dpp_transformer", "qualname": "DPPTransformerModule.eval", "type": "function", "doc": "<p>Sets the module in evaluation mode.</p>\n\n<p>This has any effect only on certain modules. See documentations of\nparticular modules for details of their behaviors in training/evaluation\nmode, if they are affected, e.g. <code>Dropout</code>, <code>BatchNorm</code>,\netc.</p>\n\n<p>This is equivalent with <code>self.train(False) &lt;torch.nn.Module.train&gt;</code>.</p>\n\n<p>See :ref:<code>locally-disable-grad-doc</code> for a comparison between\n<code>.eval()</code> and several similar mechanisms that may be confused with it.</p>\n\n<p>Returns:\n    Module: self</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.dpp_transformer.DPPTransformer", "modulename": "nlp_uncertainty_zoo.models.dpp_transformer", "qualname": "DPPTransformer", "type": "class", "doc": "<p>Transformer model using determinantal point process dropout.</p>\n", "bases": "nlp_uncertainty_zoo.models.model.Model"}, {"fullname": "nlp_uncertainty_zoo.models.dpp_transformer.DPPTransformer.__init__", "modulename": "nlp_uncertainty_zoo.models.dpp_transformer", "qualname": "DPPTransformer.__init__", "type": "function", "doc": "<p>Initialize a module.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>model_name</strong> (str):\nName of the model.</li>\n<li><strong>module_class</strong> (type):\nClass of the model that is being wrapped.</li>\n<li><strong>model_params</strong> (Dict[str, Any]):\nParameters to initialize the model.</li>\n<li><strong>device</strong> (Device):\nThe device the model is located on.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model_params</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">model_dir</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;cpu&#39;</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.dpp_transformer.DPPBertModule", "modulename": "nlp_uncertainty_zoo.models.dpp_transformer", "qualname": "DPPBertModule", "type": "class", "doc": "<p>Implementation of a transformer with determinantal point process dropout for BERT.</p>\n", "bases": "nlp_uncertainty_zoo.models.variational_transformer.VariationalBertModule"}, {"fullname": "nlp_uncertainty_zoo.models.dpp_transformer.DPPBertModule.__init__", "modulename": "nlp_uncertainty_zoo.models.dpp_transformer", "qualname": "DPPBertModule.__init__", "type": "function", "doc": "<p>Initialize a transformer.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>bert_name</strong> (str):\nName of the underlying BERT, as specified in HuggingFace transformers.</li>\n<li><strong>dropout</strong> (float):\nDropout probability.</li>\n<li><strong>num_predictions</strong> (int):\nNumber of predictions with different dropout masks.</li>\n<li><strong>is_sequence_classifier</strong> (bool):\nIndicate whether model is going to be used as a sequence classifier. Otherwise, predictions are going to\nmade at every time step.</li>\n<li><strong>device</strong> (Device):\nDevice the model is located on.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">bert_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">output_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">dropout</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">num_predictions</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">is_sequence_classifier</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">build_params</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.dpp_transformer.DPPBertModule.eval", "modulename": "nlp_uncertainty_zoo.models.dpp_transformer", "qualname": "DPPBertModule.eval", "type": "function", "doc": "<p>Sets the module in evaluation mode.</p>\n\n<p>This has any effect only on certain modules. See documentations of\nparticular modules for details of their behaviors in training/evaluation\nmode, if they are affected, e.g. <code>Dropout</code>, <code>BatchNorm</code>,\netc.</p>\n\n<p>This is equivalent with <code>self.train(False) &lt;torch.nn.Module.train&gt;</code>.</p>\n\n<p>See :ref:<code>locally-disable-grad-doc</code> for a comparison between\n<code>.eval()</code> and several similar mechanisms that may be confused with it.</p>\n\n<p>Returns:\n    Module: self</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.dpp_transformer.DPPBert", "modulename": "nlp_uncertainty_zoo.models.dpp_transformer", "qualname": "DPPBert", "type": "class", "doc": "<p>BERT model using determinantal point process dropout.</p>\n", "bases": "nlp_uncertainty_zoo.models.model.Model"}, {"fullname": "nlp_uncertainty_zoo.models.dpp_transformer.DPPBert.__init__", "modulename": "nlp_uncertainty_zoo.models.dpp_transformer", "qualname": "DPPBert.__init__", "type": "function", "doc": "<p>Initialize a module.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>model_name</strong> (str):\nName of the model.</li>\n<li><strong>module_class</strong> (type):\nClass of the model that is being wrapped.</li>\n<li><strong>model_params</strong> (Dict[str, Any]):\nParameters to initialize the model.</li>\n<li><strong>device</strong> (Device):\nThe device the model is located on.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model_params</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">model_dir</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;cpu&#39;</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.lstm", "modulename": "nlp_uncertainty_zoo.models.lstm", "type": "module", "doc": "<p>Implement a simple vanilla LSTM.</p>\n"}, {"fullname": "nlp_uncertainty_zoo.models.lstm.LSTMModule", "modulename": "nlp_uncertainty_zoo.models.lstm", "qualname": "LSTMModule", "type": "class", "doc": "<p>Implementation of a LSTM for classification.</p>\n", "bases": "nlp_uncertainty_zoo.models.model.Module"}, {"fullname": "nlp_uncertainty_zoo.models.lstm.LSTMModule.__init__", "modulename": "nlp_uncertainty_zoo.models.lstm", "qualname": "LSTMModule.__init__", "type": "function", "doc": "<p>Initialize an LSTM.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>num_layers</strong> (int):\nNumber of layers.</li>\n<li><strong>vocab_size</strong> (int):\nNumber of input vocabulary.</li>\n<li><strong>input_size</strong> (int):\nDimensionality of input to the first layer (embedding size).</li>\n<li><strong>hidden_size</strong> (int):\nSize of hidden units.</li>\n<li><strong>output_size</strong> (int):\nNumber of classes.</li>\n<li><strong>dropout</strong> (float):\nDropout probability.</li>\n<li><strong>is_sequence_classifier</strong> (bool):\nIndicate whether model is going to be used as a sequence classifier. Otherwise, predictions are going to\nmade at every time step.</li>\n<li><strong>device</strong> (Device):\nDevice the model should be moved to.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">num_layers</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">vocab_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">input_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">hidden_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">output_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">dropout</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">is_sequence_classifier</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">build_params</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.lstm.LSTMModule.forward", "modulename": "nlp_uncertainty_zoo.models.lstm", "qualname": "LSTMModule.forward", "type": "function", "doc": "<p>The forward pass of the model.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\nCurrent batch in the form of one-hot encodings.</li>\n<li><strong>hidden_states</strong> (Optional[HiddenDict]):\nDictionary of hidden and cell states by layer to initialize the model with at the first time step. If None,\nthey will be initialized with zero vectors or the ones stored under last_hidden_states if available.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Tensor of unnormalized output distributions for the current batch.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>,</span><span class=\"param\">\t<span class=\"n\">hidden_states</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.lstm.LSTMModule.get_sequence_representation", "modulename": "nlp_uncertainty_zoo.models.lstm", "qualname": "LSTMModule.get_sequence_representation", "type": "function", "doc": "<p>Define how the representation for an entire sequence is extracted from a number of hidden states. This is\nrelevant in sequence classification. For example, this could be the last hidden state for a unidirectional LSTM\nor the first hidden state for a transformer, adding a pooler layer.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>hidden</strong> (torch.FloatTensor):\nHidden states of a model for a sequence.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Representation for the current sequence.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">hidden</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.lstm.LSTMModule.get_logits", "modulename": "nlp_uncertainty_zoo.models.lstm", "qualname": "LSTMModule.get_logits", "type": "function", "doc": "<p>Get the logits for an input. Results in a tensor of size batch_size x seq_len x output_size or batch_size x\nnum_predictions x seq_len x output_size depending on the model type. Used to create inputs for the uncertainty\nmetrics defined in nlp_uncertainty_zoo.metrics.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\n(Batch of) Indexed input sequences.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Logits for current input.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.lstm.LSTMModule.init_hidden_states", "modulename": "nlp_uncertainty_zoo.models.lstm", "qualname": "LSTMModule.init_hidden_states", "type": "function", "doc": "<p>Initialize all the hidden and cell states by zero vectors, for instance in the beginning of the training or\nafter switching from test to training or vice versa.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>batch_size</strong> (int):\nSize of current batch.</li>\n<li><strong>device</strong> (Device):\nDevice of the model.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.lstm.LSTM", "modulename": "nlp_uncertainty_zoo.models.lstm", "qualname": "LSTM", "type": "class", "doc": "<p>Abstract model class. It is a wrapper that defines data loading, batching, training and evaluation loops, so that\nthe core module class can only define the model's forward pass.</p>\n", "bases": "nlp_uncertainty_zoo.models.model.Model"}, {"fullname": "nlp_uncertainty_zoo.models.lstm.LSTM.__init__", "modulename": "nlp_uncertainty_zoo.models.lstm", "qualname": "LSTM.__init__", "type": "function", "doc": "<p>Initialize a module.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>model_name</strong> (str):\nName of the model.</li>\n<li><strong>module_class</strong> (type):\nClass of the model that is being wrapped.</li>\n<li><strong>model_params</strong> (Dict[str, Any]):\nParameters to initialize the model.</li>\n<li><strong>device</strong> (Device):\nThe device the model is located on.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model_params</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">model_dir</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;cpu&#39;</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.lstm.LSTM.predict", "modulename": "nlp_uncertainty_zoo.models.lstm", "qualname": "LSTM.predict", "type": "function", "doc": "<p>Make a prediction for some input.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>X</strong> (torch.Tensor):\nInput data points.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.Tensor</strong>: Predictions.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">X</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.lstm.LayerWiseLSTM", "modulename": "nlp_uncertainty_zoo.models.lstm", "qualname": "LayerWiseLSTM", "type": "class", "doc": "<p>Model of a LSTM with a custom layer class.</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "nlp_uncertainty_zoo.models.lstm.LayerWiseLSTM.__init__", "modulename": "nlp_uncertainty_zoo.models.lstm", "qualname": "LayerWiseLSTM.__init__", "type": "function", "doc": "<p>Initialize a LSTM with a custom layer class.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>layers</strong> (List[nn.Module]):\nList of layer objects.</li>\n<li><strong>dropout</strong> (float):\nDropout probability for dropout applied between layers, except after the last layer.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">layers</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">dropout</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.lstm.LayerWiseLSTM.forward", "modulename": "nlp_uncertainty_zoo.models.lstm", "qualname": "LayerWiseLSTM.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>,</span><span class=\"param\">\t<span class=\"n\">hidden</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span><span class=\"p\">,</span> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span><span class=\"p\">]]</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.lstm.CellWiseLSTM", "modulename": "nlp_uncertainty_zoo.models.lstm", "qualname": "CellWiseLSTM", "type": "class", "doc": "<p>Model of a LSTM with a custom cell class.</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "nlp_uncertainty_zoo.models.lstm.CellWiseLSTM.__init__", "modulename": "nlp_uncertainty_zoo.models.lstm", "qualname": "CellWiseLSTM.__init__", "type": "function", "doc": "<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_size</strong> (int):\nDimensionality of input to the first layer (embedding size).</li>\n<li><strong>hidden_size</strong> (int):\nSize of hidden units.</li>\n<li><strong>dropout</strong> (float):\nDropout probability.</li>\n<li><strong>cells</strong> (List[nn.Cell]):\nList of cells, with one per layer.</li>\n<li><strong>device</strong> (Device):\nDevice the model should be moved to.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">input_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">hidden_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">dropout</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">cells</span><span class=\"p\">:</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">rnn</span><span class=\"o\">.</span><span class=\"n\">LSTMCell</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.lstm.CellWiseLSTM.forward", "modulename": "nlp_uncertainty_zoo.models.lstm", "qualname": "CellWiseLSTM.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>,</span><span class=\"param\">\t<span class=\"n\">hidden</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span><span class=\"p\">,</span> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span><span class=\"p\">]]</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.lstm_ensemble", "modulename": "nlp_uncertainty_zoo.models.lstm_ensemble", "type": "module", "doc": "<p>Implementation of an ensemble of LSTMs.</p>\n"}, {"fullname": "nlp_uncertainty_zoo.models.lstm_ensemble.LSTMEnsembleModule", "modulename": "nlp_uncertainty_zoo.models.lstm_ensemble", "qualname": "LSTMEnsembleModule", "type": "class", "doc": "<p>Implementation for an ensemble of LSTMs.</p>\n", "bases": "nlp_uncertainty_zoo.models.model.Module, nlp_uncertainty_zoo.models.model.MultiPredictionMixin"}, {"fullname": "nlp_uncertainty_zoo.models.lstm_ensemble.LSTMEnsembleModule.__init__", "modulename": "nlp_uncertainty_zoo.models.lstm_ensemble", "qualname": "LSTMEnsembleModule.__init__", "type": "function", "doc": "<p>Initialize an LSTM.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>num_layers</strong> (int):\nNumber of layers.</li>\n<li><strong>vocab_size</strong> (int):\nNumber of input vocabulary.</li>\n<li><strong>input_size</strong> (int):\nDimensionality of input to the first layer (embedding size).</li>\n<li><strong>hidden_size</strong> (int):\nSize of hidden units.</li>\n<li><strong>output_size</strong> (int):\nNumber of classes.</li>\n<li><strong>dropout</strong> (float):\nDropout probability.</li>\n<li><strong>ensemble_size</strong> (int):\nNumber of members in the ensemble.</li>\n<li><strong>is_sequence_classifier</strong> (bool):\nIndicate whether model is going to be used as a sequence classifier. Otherwise, predictions are going to\nmade at every time step.</li>\n<li><strong>device</strong> (Device):\nDevice the model should be moved to.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">num_layers</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">vocab_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">input_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">hidden_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">output_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">dropout</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">ensemble_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">is_sequence_classifier</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">build_params</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.lstm_ensemble.LSTMEnsembleModule.get_logits", "modulename": "nlp_uncertainty_zoo.models.lstm_ensemble", "qualname": "LSTMEnsembleModule.get_logits", "type": "function", "doc": "<p>Get the logits for an input. Results in a tensor of size batch_size x seq_len x output_size or batch_size x\nnum_predictions x seq_len x output_size depending on the model type. Used to create inputs for the uncertainty\nmetrics defined in nlp_uncertainty_zoo.metrics.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\n(Batch of) Indexed input sequences.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Logits for current input.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>,</span><span class=\"param\">\t<span class=\"o\">*</span><span class=\"n\">args</span>,</span><span class=\"param\">\t<span class=\"n\">num_predictions</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.lstm_ensemble.LSTMEnsembleModule.forward", "modulename": "nlp_uncertainty_zoo.models.lstm_ensemble", "qualname": "LSTMEnsembleModule.forward", "type": "function", "doc": "<p>Forward pass of the model.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\n(Batch of) Indexed input sequences.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Output predictions for input.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.lstm_ensemble.LSTMEnsembleModule.predict", "modulename": "nlp_uncertainty_zoo.models.lstm_ensemble", "qualname": "LSTMEnsembleModule.predict", "type": "function", "doc": "<p>Output a probability distribution over classes given an input. Results in a tensor of size batch_size x seq_len\nx output_size or batch_size x num_predictions x seq_len x output_size depending on the model type.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\n(Batch of) Indexed input sequences.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Logits for current input.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.lstm_ensemble.LSTMEnsembleModule.to", "modulename": "nlp_uncertainty_zoo.models.lstm_ensemble", "qualname": "LSTMEnsembleModule.to", "type": "function", "doc": "<p>Move model to another device.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>device</strong> (Device):\nDevice the model should be moved to.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.lstm_ensemble.LSTMEnsembleModule.get_sequence_representation", "modulename": "nlp_uncertainty_zoo.models.lstm_ensemble", "qualname": "LSTMEnsembleModule.get_sequence_representation", "type": "function", "doc": "<p>Create a sequence representation from an ensemble of LSTMs.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>hidden</strong> (torch.FloatTensor):\nHidden states of a model for a sequence.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Representation for the current sequence.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">hidden</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.lstm_ensemble.LSTMEnsemble", "modulename": "nlp_uncertainty_zoo.models.lstm_ensemble", "qualname": "LSTMEnsemble", "type": "class", "doc": "<p>Abstract model class. It is a wrapper that defines data loading, batching, training and evaluation loops, so that\nthe core module class can only define the model's forward pass.</p>\n", "bases": "nlp_uncertainty_zoo.models.model.Model"}, {"fullname": "nlp_uncertainty_zoo.models.lstm_ensemble.LSTMEnsemble.__init__", "modulename": "nlp_uncertainty_zoo.models.lstm_ensemble", "qualname": "LSTMEnsemble.__init__", "type": "function", "doc": "<p>Initialize a module.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>model_name</strong> (str):\nName of the model.</li>\n<li><strong>module_class</strong> (type):\nClass of the model that is being wrapped.</li>\n<li><strong>model_params</strong> (Dict[str, Any]):\nParameters to initialize the model.</li>\n<li><strong>device</strong> (Device):\nThe device the model is located on.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model_params</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">model_dir</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;cpu&#39;</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.lstm_ensemble.LSTMEnsemble.fit", "modulename": "nlp_uncertainty_zoo.models.lstm_ensemble", "qualname": "LSTMEnsemble.fit", "type": "function", "doc": "<p>Fit the model to training data.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>train_split</strong> (DataLoader):\nDataset the model is being trained on.</li>\n<li><strong>valid_split</strong> (Optional[DataLoader]):\nValidation set the model is being evaluated on if given.</li>\n<li><strong>verbose</strong> (bool):\nWhether to display information about current loss.</li>\n<li><strong>weight_loss</strong> (bool):\nWeight classes in loss function. Default is False.</li>\n<li><strong>wandb_run</strong> (Optional[WandBRun]):\nWeights and Biases run to track training statistics. Training and validation loss (if applicable) are\ntracked by default, everything else is defined in _epoch_iter() and _finetune() depending on the model.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">train_split</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataloader</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span>,</span><span class=\"param\">\t<span class=\"n\">valid_split</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataloader</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">weight_loss</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">wandb_run</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">wandb</span><span class=\"o\">.</span><span class=\"n\">sdk</span><span class=\"o\">.</span><span class=\"n\">wandb_run</span><span class=\"o\">.</span><span class=\"n\">Run</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.lstm_ensemble.LSTMEnsemble.get_loss", "modulename": "nlp_uncertainty_zoo.models.lstm_ensemble", "qualname": "LSTMEnsemble.get_loss", "type": "function", "doc": "<p>Get loss for a single batch. This just uses cross-entropy loss, but can be adjusted in subclasses by overwriting\nthis function.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>X</strong> (torch.Tensor):\nBatch input.</li>\n<li><strong>y</strong> (torch.Tensor):\nBatch labels.</li>\n<li><strong>wandb_run</strong> (Optional[WandBRun] = None):\nWeights and Biases run to track training statistics.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.Tensor</strong>: Batch loss.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">X</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">y</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">wandb_run</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">wandb</span><span class=\"o\">.</span><span class=\"n\">sdk</span><span class=\"o\">.</span><span class=\"n\">wandb_run</span><span class=\"o\">.</span><span class=\"n\">Run</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.lstm_ensemble.LSTMEnsemble.get_train_loss", "modulename": "nlp_uncertainty_zoo.models.lstm_ensemble", "qualname": "LSTMEnsemble.get_train_loss", "type": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">X</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">y</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">wandb_run</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">wandb</span><span class=\"o\">.</span><span class=\"n\">sdk</span><span class=\"o\">.</span><span class=\"n\">wandb_run</span><span class=\"o\">.</span><span class=\"n\">Run</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.model", "modulename": "nlp_uncertainty_zoo.models.model", "type": "module", "doc": "<p>Define common methods of models. This done by separating the logic into two parts:\n    * Module: This class <em>only</em> defines the model architecture and forward pass. This is also done so that others can\n      easily copy and adapt the code if necessary.\n    * Model: This wrapper class defines all the other logic necessary to use a model in practice: Training, loss\n      computation, saving and loading, etc.</p>\n"}, {"fullname": "nlp_uncertainty_zoo.models.model.Module", "modulename": "nlp_uncertainty_zoo.models.model", "qualname": "Module", "type": "class", "doc": "<p>Abstract module class, defining how the forward pass of a model looks.</p>\n", "bases": "abc.ABC, torch.nn.modules.module.Module"}, {"fullname": "nlp_uncertainty_zoo.models.model.Module.__init__", "modulename": "nlp_uncertainty_zoo.models.model", "qualname": "Module.__init__", "type": "function", "doc": "<p>Initialize a model.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>num_layers</strong> (int):\nNumber of model layers.</li>\n<li><strong>vocab_size</strong> (int):\nVocabulary size.</li>\n<li><strong>input_size</strong> (int):\nDimensionality of input to model.</li>\n<li><strong>hidden_size</strong> (int):\nSize of hidden representations.</li>\n<li><strong>output_size</strong> (int):\nSize of output of model.</li>\n<li><strong>is_sequence_classifier</strong> (bool):\nIndicate whether model is going to be used as a sequence classifier. Otherwise, predictions are going to\nmade at every time step.</li>\n<li><strong>device</strong> (Device):\nThe device the model is located on.</li>\n<li><strong>build_params</strong> (Dict[str, Any]):\nDictionary containing additional parameters used to set up the architecture.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">num_layers</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">vocab_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">input_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">hidden_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">output_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">is_sequence_classifier</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">build_params</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.model.Module.forward", "modulename": "nlp_uncertainty_zoo.models.model", "qualname": "Module.forward", "type": "function", "doc": "<p>Forward pass of the model.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\n(Batch of) Indexed input sequences.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Output predictions for input.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.model.Module.get_logits", "modulename": "nlp_uncertainty_zoo.models.model", "qualname": "Module.get_logits", "type": "function", "doc": "<p>Get the logits for an input. Results in a tensor of size batch_size x seq_len x output_size or batch_size x\nnum_predictions x seq_len x output_size depending on the model type. Used to create inputs for the uncertainty\nmetrics defined in nlp_uncertainty_zoo.metrics.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\n(Batch of) Indexed input sequences.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Logits for current input.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.model.Module.predict", "modulename": "nlp_uncertainty_zoo.models.model", "qualname": "Module.predict", "type": "function", "doc": "<p>Output a probability distribution over classes given an input. Results in a tensor of size batch_size x seq_len\nx output_size or batch_size x num_predictions x seq_len x output_size depending on the model type.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\n(Batch of) Indexed input sequences.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Logits for current input.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.model.Module.get_sequence_representation", "modulename": "nlp_uncertainty_zoo.models.model", "qualname": "Module.get_sequence_representation", "type": "function", "doc": "<p>Define how the representation for an entire sequence is extracted from a number of hidden states. This is\nrelevant in sequence classification. For example, this could be the last hidden state for a unidirectional LSTM\nor the first hidden state for a transformer, adding a pooler layer.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>hidden</strong> (torch.FloatTensor):\nHidden states of a model for a sequence.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Representation for the current sequence.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">hidden</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.model.Module.get_uncertainty", "modulename": "nlp_uncertainty_zoo.models.model", "qualname": "Module.get_uncertainty", "type": "function", "doc": "<p>Get the uncertainty scores for the current batch.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\n(Batch of) Indexed input sequences.</li>\n<li><strong>metric_name</strong> (Optional[str]):\nName of uncertainty metric being used. If None, use metric defined under the default_uncertainty_metric\nattribute.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Uncertainty scores for the current batch.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>,</span><span class=\"param\">\t<span class=\"n\">metric_name</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.model.Module.get_num_learnable_parameters", "modulename": "nlp_uncertainty_zoo.models.model", "qualname": "Module.get_num_learnable_parameters", "type": "function", "doc": "<p>Return the total number of (learnable) parameters in the model.</p>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>int</strong>: Number of learnable parameters.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">int</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.model.MultiPredictionMixin", "modulename": "nlp_uncertainty_zoo.models.model", "qualname": "MultiPredictionMixin", "type": "class", "doc": "<p>Mixin class that is used to bundle certain methods for modules that use multiple predictions to estimate\nuncertainty.</p>\n"}, {"fullname": "nlp_uncertainty_zoo.models.model.MultiPredictionMixin.__init__", "modulename": "nlp_uncertainty_zoo.models.model", "qualname": "MultiPredictionMixin.__init__", "type": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">num_predictions</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.model.Model", "modulename": "nlp_uncertainty_zoo.models.model", "qualname": "Model", "type": "class", "doc": "<p>Abstract model class. It is a wrapper that defines data loading, batching, training and evaluation loops, so that\nthe core module class can only define the model's forward pass.</p>\n", "bases": "abc.ABC"}, {"fullname": "nlp_uncertainty_zoo.models.model.Model.__init__", "modulename": "nlp_uncertainty_zoo.models.model", "qualname": "Model.__init__", "type": "function", "doc": "<p>Initialize a module.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>model_name</strong> (str):\nName of the model.</li>\n<li><strong>module_class</strong> (type):\nClass of the model that is being wrapped.</li>\n<li><strong>model_params</strong> (Dict[str, Any]):\nParameters to initialize the model.</li>\n<li><strong>device</strong> (Device):\nThe device the model is located on.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">module_class</span><span class=\"p\">:</span> <span class=\"nb\">type</span>,</span><span class=\"param\">\t<span class=\"n\">model_params</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">model_dir</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;cpu&#39;</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.model.Model.fit", "modulename": "nlp_uncertainty_zoo.models.model", "qualname": "Model.fit", "type": "function", "doc": "<p>Fit the model to training data.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>train_split</strong> (DataLoader):\nDataset the model is being trained on.</li>\n<li><strong>valid_split</strong> (Optional[DataLoader]):\nValidation set the model is being evaluated on if given.</li>\n<li><strong>verbose</strong> (bool):\nWhether to display information about current loss.</li>\n<li><strong>weight_loss</strong> (bool):\nWeight classes in loss function. Default is False.</li>\n<li><strong>wandb_run</strong> (Optional[WandBRun]):\nWeights and Biases run to track training statistics. Training and validation loss (if applicable) are\ntracked by default, everything else is defined in _epoch_iter() and _finetune() depending on the model.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">train_split</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataloader</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span>,</span><span class=\"param\">\t<span class=\"n\">valid_split</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataloader</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">weight_loss</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">wandb_run</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">wandb</span><span class=\"o\">.</span><span class=\"n\">sdk</span><span class=\"o\">.</span><span class=\"n\">wandb_run</span><span class=\"o\">.</span><span class=\"n\">Run</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.model.Model.predict", "modulename": "nlp_uncertainty_zoo.models.model", "qualname": "Model.predict", "type": "function", "doc": "<p>Make a prediction for some input.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>X</strong> (torch.Tensor):\nInput data points.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.Tensor</strong>: Predictions.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">X</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.model.Model.get_uncertainty", "modulename": "nlp_uncertainty_zoo.models.model", "qualname": "Model.get_uncertainty", "type": "function", "doc": "<p>Get the uncertainty scores for the current batch.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\n(Batch of) Indexed input sequences.</li>\n<li><strong>metric_name</strong> (Optional[str]):\nName of uncertainty metric being used. If None, use metric defined under the default_uncertainty_metric\nattribute.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Uncertainty scores for the current batch.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>,</span><span class=\"param\">\t<span class=\"o\">*</span><span class=\"n\">args</span>,</span><span class=\"param\">\t<span class=\"n\">metric_name</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.model.Model.eval", "modulename": "nlp_uncertainty_zoo.models.model", "qualname": "Model.eval", "type": "function", "doc": "<p>Evaluate a data split.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>data_split</strong> (DataSplit):\nData split the model should be evaluated on.</li>\n<li><strong>wandb_run</strong> (Optional[WandBRun]):\nWeights and Biases run to track training statistics. Training and validation loss (if applicable) are\ntracked by default, everything else is defined in _epoch_iter() and _finetune() depending on the model.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.Tensor</strong>: Loss on evaluation split.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">data_split</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataloader</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span>,</span><span class=\"param\">\t<span class=\"n\">wandb_run</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">wandb</span><span class=\"o\">.</span><span class=\"n\">sdk</span><span class=\"o\">.</span><span class=\"n\">wandb_run</span><span class=\"o\">.</span><span class=\"n\">Run</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.model.Model.get_loss", "modulename": "nlp_uncertainty_zoo.models.model", "qualname": "Model.get_loss", "type": "function", "doc": "<p>Get loss for a single batch. This just uses cross-entropy loss, but can be adjusted in subclasses by overwriting\nthis function.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>X</strong> (torch.Tensor):\nBatch input.</li>\n<li><strong>y</strong> (torch.Tensor):\nBatch labels.</li>\n<li><strong>wandb_run</strong> (Optional[WandBRun] = None):\nWeights and Biases run to track training statistics.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.Tensor</strong>: Batch loss.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">X</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">y</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">wandb_run</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">wandb</span><span class=\"o\">.</span><span class=\"n\">sdk</span><span class=\"o\">.</span><span class=\"n\">wandb_run</span><span class=\"o\">.</span><span class=\"n\">Run</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.model.Model.to", "modulename": "nlp_uncertainty_zoo.models.model", "qualname": "Model.to", "type": "function", "doc": "<p>Move model to another device.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>device</strong> (Device):\nDevice the model should be moved to.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.model.Model.load", "modulename": "nlp_uncertainty_zoo.models.model", "qualname": "Model.load", "type": "function", "doc": "<p>Load model from path.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>model_path</strong> (str):\nPath model was saved to.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>Model</strong>: Loaded model.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">model_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.sngp_transformer", "modulename": "nlp_uncertainty_zoo.models.sngp_transformer", "type": "module", "doc": "<p>Implementation of a Spectral-normalized Gaussian Process transformer as presented in\n<a href=\"https://arxiv.org/pdf/2006.10108.pdf\">Liu et al. (2020) </a>.</p>\n"}, {"fullname": "nlp_uncertainty_zoo.models.sngp_transformer.SNGPModule", "modulename": "nlp_uncertainty_zoo.models.sngp_transformer", "qualname": "SNGPModule", "type": "class", "doc": "<p>Spectral-normalized Gaussian Process output layer, as presented in\n<a href=\"https://arxiv.org/pdf/2006.10108.pdf\">Liu et al. (2020) </a>. Requires underlying model to contain residual\nconnections in order to maintain bi-Lipschitz constraint.</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "nlp_uncertainty_zoo.models.sngp_transformer.SNGPModule.__init__", "modulename": "nlp_uncertainty_zoo.models.sngp_transformer", "qualname": "SNGPModule.__init__", "type": "function", "doc": "<p>Initialize a SNGP output layer.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>hidden_size</strong> (int):\nHidden size of last regular network layer.</li>\n<li><strong>last_layer_size</strong> (int):\nSize of last layer before output layer. Called D_L in the original paper.</li>\n<li><strong>output_size</strong> (int):\nSize of output layer, so number of classes.</li>\n<li><strong>ridge_factor</strong> (float):\nFactor that identity sigma hat matrices of the SNGP layer are multiplied by.</li>\n<li><strong>scaling_coefficient</strong> (float):\nMomentum factor that is used when updating the sigma hat matrix of the SNGP layer during the last training\nepoch.</li>\n<li><strong>beta_length_scale</strong> (float):\nFactor for the variance parameter of the normal distribution all beta parameters of the SNGP layer are\ninitialized from.</li>\n<li><strong>kernel_amplitude</strong> (float):\nKernel amplitude used when computing GP features.</li>\n<li><strong>num_predictions</strong> (int):\nNumber of predictions sampled from the GP in the SNGP layer to come to the final prediction.</li>\n<li><strong>device</strong> (Device):\nDevice the replication is performed on.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">hidden_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">output_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">ridge_factor</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">scaling_coefficient</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">beta_length_scale</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">kernel_amplitude</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">num_predictions</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">build_params</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.sngp_transformer.SNGPModule.forward", "modulename": "nlp_uncertainty_zoo.models.sngp_transformer", "qualname": "SNGPModule.forward", "type": "function", "doc": "<p>Forward pass for SNGP layer.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>x</strong> (torch.FloatTensor):\nLast hidden state of underlying model.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Logits for the current batch.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.sngp_transformer.SNGPModule.predict", "modulename": "nlp_uncertainty_zoo.models.sngp_transformer", "qualname": "SNGPModule.predict", "type": "function", "doc": "<p>Get predictions for the current batch.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>x</strong> (torch.FloatTensor):\nLast hidden state of underlying model.</li>\n<li><strong>num_predictions</strong> (Optional[int]):\nNumber of predictions sampled from the GP in the SNGP layer to come to the final prediction. If None, number\nspecified during initialization is used.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Class probabilities for current batch.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>,</span><span class=\"param\">\t<span class=\"n\">num_predictions</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.sngp_transformer.SNGPModule.get_logits", "modulename": "nlp_uncertainty_zoo.models.sngp_transformer", "qualname": "SNGPModule.get_logits", "type": "function", "doc": "<p>Get the logits for an input. Results in a tensor of size batch_size x num_predictions x seq_len x output_size\ndepending on the model type.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>x</strong> (torch.LongTensor):\nInput to the model, containing all token IDs of the current batch.</li>\n<li><strong>num_predictions</strong> (int):\nNumber of predictions sampled from the GP in the SNGP layer to come to the final prediction. If None, number\nspecified during initialization is used.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Logits for the current batch.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>,</span><span class=\"param\">\t<span class=\"n\">num_predictions</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.sngp_transformer.SNGPModule.invert_sigma_hat", "modulename": "nlp_uncertainty_zoo.models.sngp_transformer", "qualname": "SNGPModule.invert_sigma_hat", "type": "function", "doc": "<p>Invert the sigma hat matrix.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.sngp_transformer.SNGPTransformerModule", "modulename": "nlp_uncertainty_zoo.models.sngp_transformer", "qualname": "SNGPTransformerModule", "type": "class", "doc": "<p>Implementation of a spectral-normalized Gaussian Process transformer.</p>\n", "bases": "nlp_uncertainty_zoo.models.spectral.SpectralTransformerModule, nlp_uncertainty_zoo.models.model.MultiPredictionMixin"}, {"fullname": "nlp_uncertainty_zoo.models.sngp_transformer.SNGPTransformerModule.__init__", "modulename": "nlp_uncertainty_zoo.models.sngp_transformer", "qualname": "SNGPTransformerModule.__init__", "type": "function", "doc": "<p>Initialize a transformer.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>num_layers</strong> (int):\nNumber of model layers.</li>\n<li><strong>vocab_size</strong> (int):\nVocabulary size.</li>\n<li><strong>input_size</strong> (int):\nDimensionality of input to model.</li>\n<li><strong>hidden_size</strong> (int):\nSize of hidden representations.</li>\n<li><strong>output_size</strong> (int):\nSize of output of model.</li>\n<li><strong>input_dropout</strong> (float):\nInput dropout added to embeddings.</li>\n<li><strong>dropout</strong> (float):\nDropout rate.</li>\n<li><strong>num_heads</strong> (int):\nNumber of self-attention heads per layer.</li>\n<li><strong>sequence_length</strong> (int):\nMaximum sequence length in dataset. Used to initialize positional embeddings.</li>\n<li><strong>spectral_norm_upper_bound</strong> (float):\nSet a limit when weight matrices will be spectrally normalized if their eigenvalue surpasses it.</li>\n<li><strong>ridge_factor</strong> (float):\nFactor that identity sigma hat matrices of the SNGP layer are multiplied by.</li>\n<li><strong>scaling_coefficient</strong> (float):\nMomentum factor that is used when updating the sigma hat matrix of the SNGP layer during the last training\nepoch.</li>\n<li><strong>beta_length_scale</strong> (float):\nFactor for the variance parameter of the normal distribution all beta parameters of the SNGP layer are\ninitialized from.</li>\n<li><strong>kernel_amplitude</strong> (float):\nKernel amplitude used when computing GP features.</li>\n<li><strong>num_predictions</strong> (int):\nNumber of predictions sampled from the GP in the SNGP layer to come to the final prediction.</li>\n<li><strong>is_sequence_classifier</strong> (bool):\nIndicate whether model is going to be used as a sequence classifier. Otherwise, predictions are going to\nmade at every time step.</li>\n<li><strong>device</strong> (Device):\nDevice the model is located on.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">num_layers</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">vocab_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">input_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">hidden_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">output_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">input_dropout</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">dropout</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">num_heads</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">sequence_length</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">spectral_norm_upper_bound</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">ridge_factor</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">scaling_coefficient</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">beta_length_scale</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">kernel_amplitude</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">num_predictions</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">is_sequence_classifier</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">build_params</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.sngp_transformer.SNGPTransformerModule.forward", "modulename": "nlp_uncertainty_zoo.models.sngp_transformer", "qualname": "SNGPTransformerModule.forward", "type": "function", "doc": "<p>Forward pass of the model.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\n(Batch of) Indexed input sequences.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Output predictions for input.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.sngp_transformer.SNGPTransformerModule.get_hidden", "modulename": "nlp_uncertainty_zoo.models.sngp_transformer", "qualname": "SNGPTransformerModule.get_hidden", "type": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.sngp_transformer.SNGPTransformerModule.get_logits", "modulename": "nlp_uncertainty_zoo.models.sngp_transformer", "qualname": "SNGPTransformerModule.get_logits", "type": "function", "doc": "<p>Get the logits for an input. Results in a tensor of size batch_size x seq_len x output_size or batch_size x\nnum_predictions x seq_len x output_size depending on the model type. Used to create inputs for the uncertainty\nmetrics defined in nlp_uncertainty_zoo.metrics.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\n(Batch of) Indexed input sequences.</li>\n<li><strong>num_predictions</strong> (int):\nNumber of predictions.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Logits for current input.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>,</span><span class=\"param\">\t<span class=\"o\">*</span><span class=\"n\">args</span>,</span><span class=\"param\">\t<span class=\"n\">num_predictions</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.sngp_transformer.SNGPTransformerModule.predict", "modulename": "nlp_uncertainty_zoo.models.sngp_transformer", "qualname": "SNGPTransformerModule.predict", "type": "function", "doc": "<p>Output a probability distribution over classes given an input. Results in a tensor of size batch_size x seq_len\nx output_size or batch_size x num_predictions x seq_len x output_size depending on the model type.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\n(Batch of) Indexed input sequences.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Logits for current input.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.sngp_transformer.SNGPTransformer", "modulename": "nlp_uncertainty_zoo.models.sngp_transformer", "qualname": "SNGPTransformer", "type": "class", "doc": "<p>Abstract model class. It is a wrapper that defines data loading, batching, training and evaluation loops, so that\nthe core module class can only define the model's forward pass.</p>\n", "bases": "nlp_uncertainty_zoo.models.model.Model"}, {"fullname": "nlp_uncertainty_zoo.models.sngp_transformer.SNGPTransformer.__init__", "modulename": "nlp_uncertainty_zoo.models.sngp_transformer", "qualname": "SNGPTransformer.__init__", "type": "function", "doc": "<p>Initialize a module.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>model_name</strong> (str):\nName of the model.</li>\n<li><strong>module_class</strong> (type):\nClass of the model that is being wrapped.</li>\n<li><strong>model_params</strong> (Dict[str, Any]):\nParameters to initialize the model.</li>\n<li><strong>device</strong> (Device):\nThe device the model is located on.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model_params</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">model_dir</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;cpu&#39;</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.sngp_transformer.SNGPBertModule", "modulename": "nlp_uncertainty_zoo.models.sngp_transformer", "qualname": "SNGPBertModule", "type": "class", "doc": "<p>Implementation of a spectral-normalized Gaussian Process transformer, based on a fine-tuned Bert.</p>\n", "bases": "nlp_uncertainty_zoo.models.spectral.SpectralBertModule, nlp_uncertainty_zoo.models.model.MultiPredictionMixin"}, {"fullname": "nlp_uncertainty_zoo.models.sngp_transformer.SNGPBertModule.__init__", "modulename": "nlp_uncertainty_zoo.models.sngp_transformer", "qualname": "SNGPBertModule.__init__", "type": "function", "doc": "<p>Initialize a BERT with spectrally-normalized Gaussian Process output layer.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>bert_name</strong> (str):\nName of the underlying BERT, as specified in HuggingFace transformers.</li>\n<li><strong>output_size</strong> (int):\nNumber of classes.</li>\n<li><strong>spectral_norm_upper_bound</strong> (float):\nSet a limit when weight matrices will be spectrally normalized if their eigenvalue surpasses it.</li>\n<li><strong>ridge_factor</strong> (float):\nFactor that identity sigma hat matrices of the SNGP layer are multiplied by.</li>\n<li><strong>scaling_coefficient</strong> (float):\nMomentum factor that is used when updating the sigma hat matrix of the SNGP layer during the last training\nepoch.</li>\n<li><strong>beta_length_scale</strong> (float):\nFactor for the variance parameter of the normal distribution all beta parameters of the SNGP layer are\ninitialized from.</li>\n<li><strong>kernel_amplitude</strong> (float):\nKernel amplitude used when computing GP features.</li>\n<li><strong>num_predictions</strong> (int):\nNumber of predictions sampled from the GP in the SNGP layer to come to the final prediction.</li>\n<li><strong>is_sequence_classifier</strong> (bool):\nIndicate whether model is going to be used as a sequence classifier. Otherwise, predictions are going to\nmade at every time step.</li>\n<li><strong>device</strong> (Device):\nDevice the model is located on.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">bert_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">output_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">spectral_norm_upper_bound</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">ridge_factor</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">scaling_coefficient</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">beta_length_scale</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">kernel_amplitude</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">num_predictions</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">is_sequence_classifier</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">build_params</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.sngp_transformer.SNGPBertModule.forward", "modulename": "nlp_uncertainty_zoo.models.sngp_transformer", "qualname": "SNGPBertModule.forward", "type": "function", "doc": "<p>Forward pass of the model.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\n(Batch of) Indexed input sequences.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Output predictions for input.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.sngp_transformer.SNGPBertModule.get_logits", "modulename": "nlp_uncertainty_zoo.models.sngp_transformer", "qualname": "SNGPBertModule.get_logits", "type": "function", "doc": "<p>Get the logits for an input. Results in a tensor of size batch_size x seq_len x output_size or batch_size x\nnum_predictions x seq_len x output_size depending on the model type. Used to create inputs for the uncertainty\nmetrics defined in nlp_uncertainty_zoo.metrics.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\n(Batch of) Indexed input sequences.</li>\n<li><strong>num_predictions</strong> (int):\nNumber of predictions.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Logits for current input.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>,</span><span class=\"param\">\t<span class=\"o\">*</span><span class=\"n\">args</span>,</span><span class=\"param\">\t<span class=\"n\">num_predictions</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.sngp_transformer.SNGPBertModule.predict", "modulename": "nlp_uncertainty_zoo.models.sngp_transformer", "qualname": "SNGPBertModule.predict", "type": "function", "doc": "<p>Output a probability distribution over classes given an input. Results in a tensor of size batch_size x seq_len\nx output_size or batch_size x num_predictions x seq_len x output_size depending on the model type.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\n(Batch of) Indexed input sequences.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Logits for current input.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.sngp_transformer.SNGPBert", "modulename": "nlp_uncertainty_zoo.models.sngp_transformer", "qualname": "SNGPBert", "type": "class", "doc": "<p>Abstract model class. It is a wrapper that defines data loading, batching, training and evaluation loops, so that\nthe core module class can only define the model's forward pass.</p>\n", "bases": "nlp_uncertainty_zoo.models.model.Model"}, {"fullname": "nlp_uncertainty_zoo.models.sngp_transformer.SNGPBert.__init__", "modulename": "nlp_uncertainty_zoo.models.sngp_transformer", "qualname": "SNGPBert.__init__", "type": "function", "doc": "<p>Initialize a module.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>model_name</strong> (str):\nName of the model.</li>\n<li><strong>module_class</strong> (type):\nClass of the model that is being wrapped.</li>\n<li><strong>model_params</strong> (Dict[str, Any]):\nParameters to initialize the model.</li>\n<li><strong>device</strong> (Device):\nThe device the model is located on.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model_params</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">model_dir</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;cpu&#39;</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.sngp_transformer.SNGPBert.get_loss", "modulename": "nlp_uncertainty_zoo.models.sngp_transformer", "qualname": "SNGPBert.get_loss", "type": "function", "doc": "<p>Get loss for a single batch. This just uses cross-entropy loss, but can be adjusted in subclasses by overwriting\nthis function.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>X</strong> (torch.Tensor):\nBatch input.</li>\n<li><strong>y</strong> (torch.Tensor):\nBatch labels.</li>\n<li><strong>wandb_run</strong> (Optional[WandBRun] = None):\nWeights and Biases run to track training statistics.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.Tensor</strong>: Batch loss.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">X</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">y</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">wandb_run</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">wandb</span><span class=\"o\">.</span><span class=\"n\">sdk</span><span class=\"o\">.</span><span class=\"n\">wandb_run</span><span class=\"o\">.</span><span class=\"n\">Run</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.spectral", "modulename": "nlp_uncertainty_zoo.models.spectral", "type": "module", "doc": "<p>Implement a superclass for transformer models that use spectral normalization to meet the bi-Lipschitz condition.\nThe following models inherit from this class:</p>\n\n<ul>\n<li>Spectral-normalized Gaussian Process (SNGP) Transformer (<code>Liu et al., 2020 &lt;https://arxiv.org/pdf/2006.10108.pdf&gt;</code>)</li>\n<li>Deterministic Uncertainty Estimation (DUE) Transformer\n(<code>Van Amersfoort et al., 2021 &lt;https://arxiv.org/pdf/2102.11409.pdf&gt;</code>)</li>\n<li>Deep Deterministic Uncertainty (DDU) Transformer (<code>Mukhoti et al., 2021 &lt;https://arxiv.org/pdf/2102.11582.pdf&gt;</code>)</li>\n</ul>\n\n<p>Utility functions from the repository of Joost van Amsterfoort (<a href=\"https://github.com/y0ast/DUE\">https://github.com/y0ast/DUE</a>) copied in here to avoid\nimport issues, since the original repository is not available as a Python package.</p>\n"}, {"fullname": "nlp_uncertainty_zoo.models.spectral.SpectralNormFC", "modulename": "nlp_uncertainty_zoo.models.spectral", "qualname": "SpectralNormFC", "type": "class", "doc": "<p></p>\n", "bases": "torch.nn.utils.spectral_norm.SpectralNorm"}, {"fullname": "nlp_uncertainty_zoo.models.spectral.SpectralNormFC.compute_weight", "modulename": "nlp_uncertainty_zoo.models.spectral", "qualname": "SpectralNormFC.compute_weight", "type": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">module</span>, </span><span class=\"param\"><span class=\"n\">do_power_iteration</span><span class=\"p\">:</span> <span class=\"nb\">bool</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.spectral.SpectralNormFC.apply", "modulename": "nlp_uncertainty_zoo.models.spectral", "qualname": "SpectralNormFC.apply", "type": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">module</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">modules</span><span class=\"o\">.</span><span class=\"n\">module</span><span class=\"o\">.</span><span class=\"n\">Module</span>,</span><span class=\"param\">\t<span class=\"n\">coeff</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">n_power_iterations</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">eps</span><span class=\"p\">:</span> <span class=\"nb\">float</span></span><span class=\"return-annotation\">) -> <span class=\"n\">nlp_uncertainty_zoo</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">spectral</span><span class=\"o\">.</span><span class=\"n\">SpectralNormFC</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.spectral.spectral_norm_fc", "modulename": "nlp_uncertainty_zoo.models.spectral", "qualname": "spectral_norm_fc", "type": "function", "doc": "<p>Args:\n    module (nn.Module): containing module\n    coeff (float, optional): coefficient to normalize to\n    n_power_iterations (int, optional): number of power iterations to\n        calculate spectral norm\n    name (str, optional): name of weight parameter\n    eps (float, optional): epsilon for numerical stability in\n        calculating norms\n    dim (int, optional): dimension corresponding to number of outputs,\n        the default is <code>0</code>, except for modules that are instances of\n        ConvTranspose{1,2,3}d, when it is <code>1</code>\nReturns:\n    The original module with the spectral norm hook\nExample::</p>\n\n<blockquote>\n  <blockquote>\n    <blockquote>\n      <p>m = spectral_norm_fc(nn.Linear(20, 40), 2.0)\n      m\n          Linear(in_features=20, out_features=40, bias=True)\n      m.weight_u.size()\n          torch.Size([40])</p>\n    </blockquote>\n  </blockquote>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">module</span>,</span><span class=\"param\">\t<span class=\"n\">coeff</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">n_power_iterations</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;weight&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">eps</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-12</span>,</span><span class=\"param\">\t<span class=\"n\">dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.spectral.SpectralTransformerModule", "modulename": "nlp_uncertainty_zoo.models.spectral", "qualname": "SpectralTransformerModule", "type": "class", "doc": "<p>Implementation of a spectrally-normalized transformer. Used as a base for models like SNGP and DDU.</p>\n", "bases": "nlp_uncertainty_zoo.models.transformer.TransformerModule"}, {"fullname": "nlp_uncertainty_zoo.models.spectral.SpectralTransformerModule.__init__", "modulename": "nlp_uncertainty_zoo.models.spectral", "qualname": "SpectralTransformerModule.__init__", "type": "function", "doc": "<p>Initialize a spectrally-normalized transformer.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>num_layers</strong> (int):\nNumber of model layers.</li>\n<li><strong>vocab_size</strong> (int):\nVocabulary size.</li>\n<li><strong>input_size</strong> (int):\nDimensionality of input to model.</li>\n<li><strong>hidden_size</strong> (int):\nSize of hidden representations.</li>\n<li><strong>output_size</strong> (int):\nSize of output of model.</li>\n<li><strong>input_dropout</strong> (float):\nDropout on word embeddings.</li>\n<li><strong>dropout</strong> (float):\nDropout rate.</li>\n<li><strong>num_heads</strong> (int):\nNumber of self-attention heads per layer.</li>\n<li><strong>sequence_length</strong> (int):\nMaximum sequence length in dataset. Used to initialize positional embeddings.</li>\n<li><strong>spectral_norm_upper_bound</strong> (float):\nSet a limit when weight matrices will be spectrally normalized if their eigenvalue surpasses it.</li>\n<li><strong>is_sequence_classifier</strong> (bool):\nIndicate whether model is going to be used as a sequence classifier. Otherwise, predictions are going to\nmade at every time step.</li>\n<li><strong>device</strong> (Device):\nDevice the model is located on.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">num_layers</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">vocab_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">input_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">hidden_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">output_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">input_dropout</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">dropout</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">num_heads</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">sequence_length</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">spectral_norm_upper_bound</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">is_sequence_classifier</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">build_params</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.spectral.SpectralBertModule", "modulename": "nlp_uncertainty_zoo.models.spectral", "qualname": "SpectralBertModule", "type": "class", "doc": "<p>Implementation of a BERT model that uses spectral normalization.</p>\n", "bases": "nlp_uncertainty_zoo.models.bert.BertModule"}, {"fullname": "nlp_uncertainty_zoo.models.spectral.SpectralBertModule.__init__", "modulename": "nlp_uncertainty_zoo.models.spectral", "qualname": "SpectralBertModule.__init__", "type": "function", "doc": "<p>Initialize a spectrally-normalized BERT.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>bert_name</strong> (str):\nName of the underlying BERT, as specified in HuggingFace transformers.</li>\n<li><strong>output_size</strong> (int):\nNumber of classes.</li>\n<li><strong>spectral_norm_upper_bound</strong> (float):\nSet a limit when weight matrices will be spectrally normalized if their eigenvalue surpasses it.</li>\n<li><strong>is_sequence_classifier</strong> (bool):\nIndicate whether model is going to be used as a sequence classifier. Otherwise, predictions are going to\nmade at every time step.</li>\n<li><strong>device</strong> (Device):\nDevice the model should be moved to.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">bert_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">output_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">spectral_norm_upper_bound</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">is_sequence_classifier</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">build_params</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.st_tau_lstm", "modulename": "nlp_uncertainty_zoo.models.st_tau_lstm", "type": "module", "doc": "<p>Implement the ST-tau LSTM by <a href=\"https://openreview.net/pdf?id=9EKHN1jOlA\">Wang et al. (2021) </a>.</p>\n"}, {"fullname": "nlp_uncertainty_zoo.models.st_tau_lstm.STTauCell", "modulename": "nlp_uncertainty_zoo.models.st_tau_lstm", "qualname": "STTauCell", "type": "class", "doc": "<p>Implementation of a ST-tau LSTM cell, based on the implementation of Wang et al. (2021) [1].\nIn contrast to the original implementation, the base cell is not a peephole-, but a normal LSTM cell.</p>\n\n<p>[1] <a href=\"https://github.com/nec-research/st_tau/blob/master/st_stau/st_tau.py\">https://github.com/nec-research/st_tau/blob/master/st_stau/st_tau.py</a></p>\n", "bases": "torch.nn.modules.rnn.LSTMCell"}, {"fullname": "nlp_uncertainty_zoo.models.st_tau_lstm.STTauCell.__init__", "modulename": "nlp_uncertainty_zoo.models.st_tau_lstm", "qualname": "STTauCell.__init__", "type": "function", "doc": "<p>Initialize a ST-tau cell.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_size</strong> (int):\nDimensionality of input to the first layer (embedding size).</li>\n<li><strong>hidden_size</strong> (int):\nSize of hidden units.</li>\n<li><strong>num_centroids</strong> (int):\nNumber of states in the underlying finite-state automaton.</li>\n<li><strong>device</strong> (Device):\nDevice the model should be moved to.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">input_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">hidden_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_centroids</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">build_params</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.st_tau_lstm.STTauCell.forward", "modulename": "nlp_uncertainty_zoo.models.st_tau_lstm", "qualname": "STTauCell.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"nb\">input</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span>,</span><span class=\"param\">\t<span class=\"n\">hx</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]]</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.st_tau_lstm.STTauLSTMModule", "modulename": "nlp_uncertainty_zoo.models.st_tau_lstm", "qualname": "STTauLSTMModule", "type": "class", "doc": "<p>Implementation of a ST-tau LSTM by Wang et al. (2021).</p>\n", "bases": "nlp_uncertainty_zoo.models.lstm.LSTMModule, nlp_uncertainty_zoo.models.model.MultiPredictionMixin"}, {"fullname": "nlp_uncertainty_zoo.models.st_tau_lstm.STTauLSTMModule.__init__", "modulename": "nlp_uncertainty_zoo.models.st_tau_lstm", "qualname": "STTauLSTMModule.__init__", "type": "function", "doc": "<p>Initialize a ST-tau LSTM.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>num_layers</strong> (int):\nNumber of layers.</li>\n<li><strong>vocab_size</strong> (int):\nNumber of input vocabulary.</li>\n<li><strong>input_size</strong> (int):\nDimensionality of input to the first layer (embedding size).</li>\n<li><strong>hidden_size</strong> (int):\nSize of hidden units.</li>\n<li><strong>output_size</strong> (int):\nNumber of classes.</li>\n<li><strong>dropout</strong> (float):\nDropout probability.</li>\n<li><strong>num_centroids</strong> (int):\nNumber of states in the underlying finite-state automaton.</li>\n<li><strong>num_predictions</strong> (int):\nNumber of predictions (forward passes) used to make predictions.</li>\n<li><strong>is_sequence_classifier</strong> (bool):\nIndicate whether model is going to be used as a sequence classifier. Otherwise, predictions are going to\nmade at every time step.</li>\n<li><strong>device</strong> (Device):\nDevice the model should be moved to.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">num_layers</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">vocab_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">input_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">hidden_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">output_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">dropout</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">num_centroids</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_predictions</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">is_sequence_classifier</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">build_params</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.st_tau_lstm.STTauLSTMModule.get_logits", "modulename": "nlp_uncertainty_zoo.models.st_tau_lstm", "qualname": "STTauLSTMModule.get_logits", "type": "function", "doc": "<p>Get the logits for an input. Results in a tensor of size batch_size x seq_len x output_size or batch_size x\nnum_predictions x seq_len x output_size depending on the model type. Used to create inputs for the uncertainty\nmetrics defined in nlp_uncertainty_zoo.metrics.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\n(Batch of) Indexed input sequences.</li>\n<li><strong>num_predictions</strong> (Optional[int]):\nNumber of predictions (forward passes) used to make predictions.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Logits for current input.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>,</span><span class=\"param\">\t<span class=\"o\">*</span><span class=\"n\">args</span>,</span><span class=\"param\">\t<span class=\"n\">num_predictions</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.st_tau_lstm.STTauLSTMModule.predict", "modulename": "nlp_uncertainty_zoo.models.st_tau_lstm", "qualname": "STTauLSTMModule.predict", "type": "function", "doc": "<p>Output a probability distribution over classes given an input. Results in a tensor of size batch_size x seq_len\nx output_size or batch_size x num_predictions x seq_len x output_size depending on the model type.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\n(Batch of) Indexed input sequences.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Logits for current input.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.st_tau_lstm.STTauLSTM", "modulename": "nlp_uncertainty_zoo.models.st_tau_lstm", "qualname": "STTauLSTM", "type": "class", "doc": "<p>Abstract model class. It is a wrapper that defines data loading, batching, training and evaluation loops, so that\nthe core module class can only define the model's forward pass.</p>\n", "bases": "nlp_uncertainty_zoo.models.model.Model"}, {"fullname": "nlp_uncertainty_zoo.models.st_tau_lstm.STTauLSTM.__init__", "modulename": "nlp_uncertainty_zoo.models.st_tau_lstm", "qualname": "STTauLSTM.__init__", "type": "function", "doc": "<p>Initialize a module.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>model_name</strong> (str):\nName of the model.</li>\n<li><strong>module_class</strong> (type):\nClass of the model that is being wrapped.</li>\n<li><strong>model_params</strong> (Dict[str, Any]):\nParameters to initialize the model.</li>\n<li><strong>device</strong> (Device):\nThe device the model is located on.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model_params</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">model_dir</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;cpu&#39;</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.transformer", "modulename": "nlp_uncertainty_zoo.models.transformer", "type": "module", "doc": "<p>Implement a vanilla transformer model.</p>\n"}, {"fullname": "nlp_uncertainty_zoo.models.transformer.TransformerModule", "modulename": "nlp_uncertainty_zoo.models.transformer", "qualname": "TransformerModule", "type": "class", "doc": "<p>Implementation of a transformer for classification.</p>\n", "bases": "nlp_uncertainty_zoo.models.model.Module"}, {"fullname": "nlp_uncertainty_zoo.models.transformer.TransformerModule.__init__", "modulename": "nlp_uncertainty_zoo.models.transformer", "qualname": "TransformerModule.__init__", "type": "function", "doc": "<p>Initialize a transformer.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>num_layers</strong> (int):\nNumber of model layers.</li>\n<li><strong>vocab_size</strong> (int):\nVocabulary size.</li>\n<li><strong>input_size</strong> (int):\nDimensionality of input to model.</li>\n<li><strong>hidden_size</strong> (int):\nSize of hidden representations.</li>\n<li><strong>output_size</strong> (int):\nSize of output of model.</li>\n<li><strong>input_dropout</strong> (float):\nDropout on word embeddings.</li>\n<li><strong>dropout</strong> (float):\nDropout rate.</li>\n<li><strong>num_heads</strong> (int):\nNumber of self-attention heads per layer.</li>\n<li><strong>sequence_length</strong> (int):\nMaximum sequence length in dataset. Used to initialize positional embeddings.</li>\n<li><strong>is_sequence_classifier</strong> (bool):\nIndicate whether model is going to be used as a sequence classifier. Otherwise, predictions are going to\nmade at every time step.</li>\n<li><strong>device</strong> (Device):\nDevice the model is located on.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">num_layers</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">vocab_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">input_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">hidden_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">output_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">input_dropout</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">dropout</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">num_heads</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">sequence_length</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">is_sequence_classifier</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">build_params</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.transformer.TransformerModule.forward", "modulename": "nlp_uncertainty_zoo.models.transformer", "qualname": "TransformerModule.forward", "type": "function", "doc": "<p>Forward pass of the model.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\n(Batch of) Indexed input sequences.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Output predictions for input.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.transformer.TransformerModule.get_hidden", "modulename": "nlp_uncertainty_zoo.models.transformer", "qualname": "TransformerModule.get_hidden", "type": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.transformer.TransformerModule.get_logits", "modulename": "nlp_uncertainty_zoo.models.transformer", "qualname": "TransformerModule.get_logits", "type": "function", "doc": "<p>Get the logits for an input. Results in a tensor of size batch_size x seq_len x output_size or batch_size x\nnum_predictions x seq_len x output_size depending on the model type. Used to create inputs for the uncertainty\nmetrics defined in nlp_uncertainty_zoo.metrics.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\n(Batch of) Indexed input sequences.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Logits for current input.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.transformer.TransformerModule.get_sequence_representation", "modulename": "nlp_uncertainty_zoo.models.transformer", "qualname": "TransformerModule.get_sequence_representation", "type": "function", "doc": "<p>Define how the representation for an entire sequence is extracted from a number of hidden states. This is\nrelevant in sequence classification. In this case this is done by using the first hidden state and adding a\npooler layer.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>hidden</strong> (torch.FloatTensor):\nHidden states of a model for a sequence.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Representation for the current sequence.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">hidden</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.transformer.Transformer", "modulename": "nlp_uncertainty_zoo.models.transformer", "qualname": "Transformer", "type": "class", "doc": "<p>Abstract model class. It is a wrapper that defines data loading, batching, training and evaluation loops, so that\nthe core module class can only define the model's forward pass.</p>\n", "bases": "nlp_uncertainty_zoo.models.model.Model"}, {"fullname": "nlp_uncertainty_zoo.models.transformer.Transformer.__init__", "modulename": "nlp_uncertainty_zoo.models.transformer", "qualname": "Transformer.__init__", "type": "function", "doc": "<p>Initialize a module.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>model_name</strong> (str):\nName of the model.</li>\n<li><strong>module_class</strong> (type):\nClass of the model that is being wrapped.</li>\n<li><strong>model_params</strong> (Dict[str, Any]):\nParameters to initialize the model.</li>\n<li><strong>device</strong> (Device):\nThe device the model is located on.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model_params</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">model_dir</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;cpu&#39;</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.transformer.PositionalEmbedding", "modulename": "nlp_uncertainty_zoo.models.transformer", "qualname": "PositionalEmbedding", "type": "class", "doc": "<p>Implementation of positional embeddings, shamelessly copied and adapted from the corresponding\n<a href=\"https://github.com/pytorch/tutorials/blob/master/beginner_source/transformer_tutorial.py\">PyTorch example </a>.</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "nlp_uncertainty_zoo.models.transformer.PositionalEmbedding.__init__", "modulename": "nlp_uncertainty_zoo.models.transformer", "qualname": "PositionalEmbedding.__init__", "type": "function", "doc": "<p>Initialize positional embeddings.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>sequence_length</strong> (int):\nMaximum sequence length in dataset. Used to initialize positional embeddings.</li>\n<li><strong>input_size</strong> (int):\nDimensionality of input to model.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">sequence_length</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">input_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.transformer.PositionalEmbedding.forward", "modulename": "nlp_uncertainty_zoo.models.transformer", "qualname": "PositionalEmbedding.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.variational_lstm", "modulename": "nlp_uncertainty_zoo.models.variational_lstm", "type": "module", "doc": "<p>Implementation of a variational LSTM, as presented by\n<code>Gal &amp; Ghrahramani (2016b) &lt;https://arxiv.org/pdf/1512.05287.pdf&gt;</code>.</p>\n"}, {"fullname": "nlp_uncertainty_zoo.models.variational_lstm.VariationalDropout", "modulename": "nlp_uncertainty_zoo.models.variational_lstm", "qualname": "VariationalDropout", "type": "class", "doc": "<p>Variational Dropout module. In comparison to the default PyTorch module, this one only changes the dropout mask when\nsample() is called.</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "nlp_uncertainty_zoo.models.variational_lstm.VariationalDropout.__init__", "modulename": "nlp_uncertainty_zoo.models.variational_lstm", "qualname": "VariationalDropout.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">dropout</span><span class=\"p\">:</span> <span class=\"nb\">float</span>, </span><span class=\"param\"><span class=\"n\">input_dim</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.variational_lstm.VariationalDropout.forward", "modulename": "nlp_uncertainty_zoo.models.variational_lstm", "qualname": "VariationalDropout.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.variational_lstm.VariationalDropout.sample", "modulename": "nlp_uncertainty_zoo.models.variational_lstm", "qualname": "VariationalDropout.sample", "type": "function", "doc": "<p>Sample a new dropout mask for a batch of specified size.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>batch_size</strong> (int):\nSize of current batch.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.variational_lstm.VariationalLSTMModule", "modulename": "nlp_uncertainty_zoo.models.variational_lstm", "qualname": "VariationalLSTMModule", "type": "class", "doc": "<p>Variational LSTM as described in <code>Gal &amp; Ghrahramani (2016b) &lt;https://arxiv.org/pdf/1512.05287.pdf&gt;</code>, where the same\ndropout mask is being reused throughout a batch for connection of the same type.</p>\n\n<p>The only difference compared to the original implementation is that the embedding dropout works like normal dropout,\nnot dropping out specific types. This was observed to yield minor improvement during experiments and simplified the\nimplementation.</p>\n", "bases": "nlp_uncertainty_zoo.models.model.Module, nlp_uncertainty_zoo.models.model.MultiPredictionMixin"}, {"fullname": "nlp_uncertainty_zoo.models.variational_lstm.VariationalLSTMModule.__init__", "modulename": "nlp_uncertainty_zoo.models.variational_lstm", "qualname": "VariationalLSTMModule.__init__", "type": "function", "doc": "<p>Initialize a variational LSTM.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>num_layers</strong> (int):\nNumber of layers.</li>\n<li><strong>vocab_size</strong> (int):\nNumber of input vocabulary.</li>\n<li><strong>input_size</strong> (int):\nDimensionality of input to the first layer (embedding size).</li>\n<li><strong>hidden_size</strong> (int):\nSize of hidden units.</li>\n<li><strong>output_size</strong> (int):\nNumber of classes.</li>\n<li><strong>embedding_dropout</strong> (float):\nDropout probability for the input embeddings.</li>\n<li><strong>layer_dropout</strong> (float):\nDropout probability for hidden states between layers.</li>\n<li><strong>time_dropout</strong> (float):\nDropout probability for hidden states between time steps.</li>\n<li><strong>num_predictions</strong> (int):\nNumber of predictions (forward passes) used to make predictions.</li>\n<li><strong>is_sequence_classifier</strong> (bool):\nIndicate whether model is going to be used as a sequence classifier. Otherwise, predictions are going to\nmade at every time step.</li>\n<li><strong>device</strong> (Device):\nDevice the model should be moved to.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">num_layers</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">vocab_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">input_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">hidden_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">output_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">embedding_dropout</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">layer_dropout</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">time_dropout</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">num_predictions</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">is_sequence_classifier</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">build_params</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.variational_lstm.VariationalLSTMModule.forward", "modulename": "nlp_uncertainty_zoo.models.variational_lstm", "qualname": "VariationalLSTMModule.forward", "type": "function", "doc": "<p>The forward pass of the model.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\nCurrent batch in the form of one-hot encodings.</li>\n<li><strong>hidden_states</strong> (Optional[HiddenDict]):\nDictionary of hidden and cell states by layer to initialize the model with at the first time step. If None,\nthey will be initialized with zero vectors or the ones stored under last_hidden_states if available.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Tensor of unnormalized output distributions for the current batch.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>,</span><span class=\"param\">\t<span class=\"n\">hidden_states</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.variational_lstm.VariationalLSTMModule.predict", "modulename": "nlp_uncertainty_zoo.models.variational_lstm", "qualname": "VariationalLSTMModule.predict", "type": "function", "doc": "<p>Make a prediction for some input.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\nCurrent batch in the form of one-hot encodings.</li>\n<li><strong>hidden_states</strong> (Optional[HiddenDict]):\nDictionary of hidden and cell states by layer to initialize the model with at the first time step. If None,\nthey will be initialized with zero vectors or the ones stored under last_hidden_states if available.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Class probabilities for the current batch.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>,</span><span class=\"param\">\t<span class=\"n\">hidden_states</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span><span class=\"p\">],</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.variational_lstm.VariationalLSTMModule.init_hidden_states", "modulename": "nlp_uncertainty_zoo.models.variational_lstm", "qualname": "VariationalLSTMModule.init_hidden_states", "type": "function", "doc": "<p>Initialize all the hidden and cell states by zero vectors, for instance in the beginning of the training or\nafter switching from test to training or vice versa.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>batch_size</strong> (int):\nSize of current batch.</li>\n<li><strong>device</strong> (Device):\nDevice of the model.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.variational_lstm.VariationalLSTMModule.get_sequence_representation", "modulename": "nlp_uncertainty_zoo.models.variational_lstm", "qualname": "VariationalLSTMModule.get_sequence_representation", "type": "function", "doc": "<p>Define how the representation for an entire sequence is extracted from a number of hidden states. This is\nrelevant in sequence classification. For example, this could be the last hidden state for a unidirectional LSTM\nor the first hidden state for a transformer, adding a pooler layer.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>hidden</strong> (torch.FloatTensor):\nHidden states of a model for a sequence.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Representation for the current sequence.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">hidden</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.variational_lstm.VariationalLSTMModule.get_logits", "modulename": "nlp_uncertainty_zoo.models.variational_lstm", "qualname": "VariationalLSTMModule.get_logits", "type": "function", "doc": "<p>Get the logits for an input. Results in a tensor of size batch_size x seq_len x output_size or batch_size x\nnum_predictions x seq_len x output_size depending on the model type. Used to create inputs for the uncertainty\nmetrics defined in nlp_uncertainty_zoo.metrics.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\n(Batch of) Indexed input sequences.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Logits for current input.</li>\n<li><strong>num_predictions</strong> (Optional[int]):\nNumber of predictions (forward passes) used to make predictions.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>,</span><span class=\"param\">\t<span class=\"o\">*</span><span class=\"n\">args</span>,</span><span class=\"param\">\t<span class=\"n\">num_predictions</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.variational_lstm.VariationalLSTMModule.sample_masks", "modulename": "nlp_uncertainty_zoo.models.variational_lstm", "qualname": "VariationalLSTMModule.sample_masks", "type": "function", "doc": "<p>Sample masks for the current batch.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>batch_size</strong> (int):\nSize of the current batch.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.variational_lstm.VariationalLSTM", "modulename": "nlp_uncertainty_zoo.models.variational_lstm", "qualname": "VariationalLSTM", "type": "class", "doc": "<p>Module for the variational LSTM.</p>\n", "bases": "nlp_uncertainty_zoo.models.model.Model"}, {"fullname": "nlp_uncertainty_zoo.models.variational_lstm.VariationalLSTM.__init__", "modulename": "nlp_uncertainty_zoo.models.variational_lstm", "qualname": "VariationalLSTM.__init__", "type": "function", "doc": "<p>Initialize a module.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>model_name</strong> (str):\nName of the model.</li>\n<li><strong>module_class</strong> (type):\nClass of the model that is being wrapped.</li>\n<li><strong>model_params</strong> (Dict[str, Any]):\nParameters to initialize the model.</li>\n<li><strong>device</strong> (Device):\nThe device the model is located on.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model_params</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">model_dir</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;cpu&#39;</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.variational_transformer", "modulename": "nlp_uncertainty_zoo.models.variational_transformer", "type": "module", "doc": "<p>Implement the variational transformer, as presented by <a href=\"https://arxiv.org/pdf/2006.08344.pdf\">(Xiao et al., 2021) </a>.</p>\n"}, {"fullname": "nlp_uncertainty_zoo.models.variational_transformer.VariationalTransformerModule", "modulename": "nlp_uncertainty_zoo.models.variational_transformer", "qualname": "VariationalTransformerModule", "type": "class", "doc": "<p>Implementation of Variational Transformer by <a href=\"https://arxiv.org/pdf/2006.08344.pdf\">Xiao et al., (2021) </a>.</p>\n", "bases": "nlp_uncertainty_zoo.models.transformer.TransformerModule, nlp_uncertainty_zoo.models.model.MultiPredictionMixin"}, {"fullname": "nlp_uncertainty_zoo.models.variational_transformer.VariationalTransformerModule.__init__", "modulename": "nlp_uncertainty_zoo.models.variational_transformer", "qualname": "VariationalTransformerModule.__init__", "type": "function", "doc": "<p>Initialize a transformer.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>num_layers</strong> (int):\nNumber of model layers.</li>\n<li><strong>vocab_size</strong> (int):\nVocabulary size.</li>\n<li><strong>input_size</strong> (int):\nDimensionality of input to model.</li>\n<li><strong>hidden_size</strong> (int):\nSize of hidden representations.</li>\n<li><strong>output_size</strong> (int):\nSize of output of model.</li>\n<li><strong>input_dropout</strong> (float):\nDropout on word embeddings.</li>\n<li><strong>dropout</strong> (float):\nDropout rate.</li>\n<li><strong>num_heads</strong> (int):\nNumber of self-attention heads per layer.</li>\n<li><strong>sequence_length</strong> (int):\nMaximum sequence length in dataset. Used to initialize positional embeddings.</li>\n<li><strong>num_predictions</strong> (int):\nNumber of predictions with different dropout masks.</li>\n<li><strong>is_sequence_classifier</strong> (bool):\nIndicate whether model is going to be used as a sequence classifier. Otherwise, predictions are going to\nmade at every time step.</li>\n<li><strong>device</strong> (Device):\nDevice the model is located on.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">num_layers</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">vocab_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">input_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">hidden_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">output_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">input_dropout</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">dropout</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">num_heads</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">sequence_length</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_predictions</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">is_sequence_classifier</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">build_params</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.variational_transformer.VariationalTransformerModule.get_logits", "modulename": "nlp_uncertainty_zoo.models.variational_transformer", "qualname": "VariationalTransformerModule.get_logits", "type": "function", "doc": "<p>Get the logits for an input. Results in a tensor of size batch_size x seq_len x output_size or batch_size x\nnum_predictions x seq_len x output_size depending on the model type. Used to create inputs for the uncertainty\nmetrics defined in nlp_uncertainty_zoo.metrics.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\n(Batch of) Indexed input sequences.</li>\n<li><strong>num_predictions</strong> (Optional[int]):\nNumber of predictions (number of forward passes).</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Logits for current input.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>,</span><span class=\"param\">\t<span class=\"o\">*</span><span class=\"n\">args</span>,</span><span class=\"param\">\t<span class=\"n\">num_predictions</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.variational_transformer.VariationalTransformerModule.predict", "modulename": "nlp_uncertainty_zoo.models.variational_transformer", "qualname": "VariationalTransformerModule.predict", "type": "function", "doc": "<p>Output a probability distribution over classes given an input. Results in a tensor of size batch_size x seq_len\nx output_size or batch_size x num_predictions x seq_len x output_size depending on the model type.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\n(Batch of) Indexed input sequences.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Logits for current input.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.variational_transformer.VariationalTransformerModule.eval", "modulename": "nlp_uncertainty_zoo.models.variational_transformer", "qualname": "VariationalTransformerModule.eval", "type": "function", "doc": "<p>Sets the module in evaluation mode.</p>\n\n<p>This has any effect only on certain modules. See documentations of\nparticular modules for details of their behaviors in training/evaluation\nmode, if they are affected, e.g. <code>Dropout</code>, <code>BatchNorm</code>,\netc.</p>\n\n<p>This is equivalent with <code>self.train(False) &lt;torch.nn.Module.train&gt;</code>.</p>\n\n<p>See :ref:<code>locally-disable-grad-doc</code> for a comparison between\n<code>.eval()</code> and several similar mechanisms that may be confused with it.</p>\n\n<p>Returns:\n    Module: self</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.variational_transformer.VariationalBertModule", "modulename": "nlp_uncertainty_zoo.models.variational_transformer", "qualname": "VariationalBertModule", "type": "class", "doc": "<p>Implementation of Variational Transformer by <a href=\"https://arxiv.org/pdf/2006.08344.pdf\">Xiao et al., (2021) </a> for BERT.</p>\n", "bases": "nlp_uncertainty_zoo.models.bert.BertModule, nlp_uncertainty_zoo.models.model.MultiPredictionMixin"}, {"fullname": "nlp_uncertainty_zoo.models.variational_transformer.VariationalBertModule.__init__", "modulename": "nlp_uncertainty_zoo.models.variational_transformer", "qualname": "VariationalBertModule.__init__", "type": "function", "doc": "<p>Initialize a transformer.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>bert_name</strong> (str):\nName of the BERT to be used.</li>\n<li><strong>dropout</strong> (float):\nDropout probability.</li>\n<li><strong>num_predictions</strong> (int):\nNumber of predictions with different dropout masks.</li>\n<li><strong>is_sequence_classifier</strong> (bool):\nIndicate whether model is going to be used as a sequence classifier. Otherwise, predictions are going to\nmade at every time step.</li>\n<li><strong>device</strong> (Device):\nDevice the model is located on.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">bert_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">output_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">dropout</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">num_predictions</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">is_sequence_classifier</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">build_params</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.variational_transformer.VariationalBertModule.get_logits", "modulename": "nlp_uncertainty_zoo.models.variational_transformer", "qualname": "VariationalBertModule.get_logits", "type": "function", "doc": "<p>Get the logits for an input. Results in a tensor of size batch_size x seq_len x output_size or batch_size x\nnum_predictions x seq_len x output_size depending on the model type. Used to create inputs for the uncertainty\nmetrics defined in nlp_uncertainty_zoo.metrics.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\n(Batch of) Indexed input sequences.</li>\n<li><strong>num_predictions</strong> (Optional[int]):\nNumber of predictions (number of forward passes).</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Logits for current input.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>,</span><span class=\"param\">\t<span class=\"o\">*</span><span class=\"n\">args</span>,</span><span class=\"param\">\t<span class=\"n\">num_predictions</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.variational_transformer.VariationalBertModule.predict", "modulename": "nlp_uncertainty_zoo.models.variational_transformer", "qualname": "VariationalBertModule.predict", "type": "function", "doc": "<p>Output a probability distribution over classes given an input. Results in a tensor of size batch_size x seq_len\nx output_size or batch_size x num_predictions x seq_len x output_size depending on the model type.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>input_</strong> (torch.LongTensor):\n(Batch of) Indexed input sequences.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Logits for current input.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">input_</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">kwargs</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.variational_transformer.VariationalBertModule.eval", "modulename": "nlp_uncertainty_zoo.models.variational_transformer", "qualname": "VariationalBertModule.eval", "type": "function", "doc": "<p>Sets the module in evaluation mode.</p>\n\n<p>This has any effect only on certain modules. See documentations of\nparticular modules for details of their behaviors in training/evaluation\nmode, if they are affected, e.g. <code>Dropout</code>, <code>BatchNorm</code>,\netc.</p>\n\n<p>This is equivalent with <code>self.train(False) &lt;torch.nn.Module.train&gt;</code>.</p>\n\n<p>See :ref:<code>locally-disable-grad-doc</code> for a comparison between\n<code>.eval()</code> and several similar mechanisms that may be confused with it.</p>\n\n<p>Returns:\n    Module: self</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">args</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.models.variational_transformer.VariationalTransformer", "modulename": "nlp_uncertainty_zoo.models.variational_transformer", "qualname": "VariationalTransformer", "type": "class", "doc": "<p>Module for the variational transformer.</p>\n", "bases": "nlp_uncertainty_zoo.models.model.Model"}, {"fullname": "nlp_uncertainty_zoo.models.variational_transformer.VariationalTransformer.__init__", "modulename": "nlp_uncertainty_zoo.models.variational_transformer", "qualname": "VariationalTransformer.__init__", "type": "function", "doc": "<p>Initialize a module.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>model_name</strong> (str):\nName of the model.</li>\n<li><strong>module_class</strong> (type):\nClass of the model that is being wrapped.</li>\n<li><strong>model_params</strong> (Dict[str, Any]):\nParameters to initialize the model.</li>\n<li><strong>device</strong> (Device):\nThe device the model is located on.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model_params</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">model_dir</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;cpu&#39;</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.models.variational_transformer.VariationalBert", "modulename": "nlp_uncertainty_zoo.models.variational_transformer", "qualname": "VariationalBert", "type": "class", "doc": "<p>Variational version of BERT.</p>\n", "bases": "nlp_uncertainty_zoo.models.model.Model"}, {"fullname": "nlp_uncertainty_zoo.models.variational_transformer.VariationalBert.__init__", "modulename": "nlp_uncertainty_zoo.models.variational_transformer", "qualname": "VariationalBert.__init__", "type": "function", "doc": "<p>Initialize a module.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>model_name</strong> (str):\nName of the model.</li>\n<li><strong>module_class</strong> (type):\nClass of the model that is being wrapped.</li>\n<li><strong>model_params</strong> (Dict[str, Any]):\nParameters to initialize the model.</li>\n<li><strong>device</strong> (Device):\nThe device the model is located on.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model_params</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">model_dir</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"nb\">str</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;cpu&#39;</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.tests.__init__", "modulename": "nlp_uncertainty_zoo.tests.__init__", "type": "module", "doc": "<p></p>\n"}, {"fullname": "nlp_uncertainty_zoo.tests.test_module_functions", "modulename": "nlp_uncertainty_zoo.tests.test_module_functions", "type": "module", "doc": "<p>Make sure that all functions for available models work as expected and are implemented correctly. Specifically,\nthis concerned the following points:\n    - Functions such as get_logits(), predict(), get_sequence_representation()\n    - Uncertainty metrics\n    - All the above for both LanguageModelingDataset and SequenceClassificationDataset</p>\n\n<p>Most importantly, this <em>doesn't</em> include testing the correctness of models. It rather aims to guarantee consistency\nacross model implementations.</p>\n"}, {"fullname": "nlp_uncertainty_zoo.tests.test_module_functions.MockDatasetBuilder", "modulename": "nlp_uncertainty_zoo.tests.test_module_functions", "qualname": "MockDatasetBuilder", "type": "class", "doc": "<p>Create a mock language modeling dataset.</p>\n", "bases": "abc.ABC"}, {"fullname": "nlp_uncertainty_zoo.tests.test_module_functions.MockDatasetBuilder.__init__", "modulename": "nlp_uncertainty_zoo.tests.test_module_functions", "qualname": "MockDatasetBuilder.__init__", "type": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">num_instances</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">num_types</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">sequence_length</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.tests.test_module_functions.MockLanguageModellingDatasetBuilder", "modulename": "nlp_uncertainty_zoo.tests.test_module_functions", "qualname": "MockLanguageModellingDatasetBuilder", "type": "class", "doc": "<p>Create a mock language modeling dataset.</p>\n", "bases": "MockDatasetBuilder"}, {"fullname": "nlp_uncertainty_zoo.tests.test_module_functions.MockLanguageModellingDatasetBuilder.__init__", "modulename": "nlp_uncertainty_zoo.tests.test_module_functions", "qualname": "MockLanguageModellingDatasetBuilder.__init__", "type": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">num_instances</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">num_types</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">sequence_length</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.tests.test_module_functions.MockLanguageModellingDatasetBuilder.build", "modulename": "nlp_uncertainty_zoo.tests.test_module_functions", "qualname": "MockLanguageModellingDatasetBuilder.build", "type": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataloader</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.tests.test_module_functions.MockSequenceClassificationDatasetBuilder", "modulename": "nlp_uncertainty_zoo.tests.test_module_functions", "qualname": "MockSequenceClassificationDatasetBuilder", "type": "class", "doc": "<p>Create a mock language modeling dataset.</p>\n", "bases": "MockDatasetBuilder"}, {"fullname": "nlp_uncertainty_zoo.tests.test_module_functions.MockSequenceClassificationDatasetBuilder.__init__", "modulename": "nlp_uncertainty_zoo.tests.test_module_functions", "qualname": "MockSequenceClassificationDatasetBuilder.__init__", "type": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">num_instances</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_types</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">sequence_length</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_classes</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.tests.test_module_functions.MockSequenceClassificationDatasetBuilder.build", "modulename": "nlp_uncertainty_zoo.tests.test_module_functions", "qualname": "MockSequenceClassificationDatasetBuilder.build", "type": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataloader</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.tests.test_module_functions.AbstractFunctionTests", "modulename": "nlp_uncertainty_zoo.tests.test_module_functions", "qualname": "AbstractFunctionTests", "type": "class", "doc": "<p>Abstract base class, implementing all tests to check important model functions and their consistency across     implemented models.</p>\n", "bases": "unittest.case.TestCase, abc.ABC"}, {"fullname": "nlp_uncertainty_zoo.tests.test_module_functions.AbstractFunctionTests.trained_models", "modulename": "nlp_uncertainty_zoo.tests.test_module_functions", "qualname": "AbstractFunctionTests.trained_models", "type": "variable", "doc": "<p>Returns a generator of trained models to avoid having to hold all trained models in memory.</p>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>Generator[Model]</strong>: Generator that returns one of the available models in trained form during every iteration.</li>\n</ul>\n", "annotation": ": Generator[Tuple[str, nlp_uncertainty_zoo.models.model.Model], NoneType, NoneType]"}, {"fullname": "nlp_uncertainty_zoo.tests.test_module_functions.AbstractFunctionTests.test_all", "modulename": "nlp_uncertainty_zoo.tests.test_module_functions", "qualname": "AbstractFunctionTests.test_all", "type": "function", "doc": "<p>Test all important functionalities of all models for consistency. Check the called functions for more details.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.tests.test_module_functions.LanguageModelingFunctionTests", "modulename": "nlp_uncertainty_zoo.tests.test_module_functions", "qualname": "LanguageModelingFunctionTests", "type": "class", "doc": "<p>Test all important model functionalities for a language modeling dataset.</p>\n", "bases": "AbstractFunctionTests"}, {"fullname": "nlp_uncertainty_zoo.tests.test_module_functions.LanguageModelingFunctionTests.setUp", "modulename": "nlp_uncertainty_zoo.tests.test_module_functions", "qualname": "LanguageModelingFunctionTests.setUp", "type": "function", "doc": "<p>Hook method for setting up the test fixture before exercising it.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.tests.test_module_functions.SequenceClassificationFunctionTests", "modulename": "nlp_uncertainty_zoo.tests.test_module_functions", "qualname": "SequenceClassificationFunctionTests", "type": "class", "doc": "<p>Test all important model functionalities for a sequuence classification dataset.</p>\n", "bases": "AbstractFunctionTests"}, {"fullname": "nlp_uncertainty_zoo.tests.test_module_functions.SequenceClassificationFunctionTests.setUp", "modulename": "nlp_uncertainty_zoo.tests.test_module_functions", "qualname": "SequenceClassificationFunctionTests.setUp", "type": "function", "doc": "<p>Hook method for setting up the test fixture before exercising it.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"kc\">None</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.utils.__init__", "modulename": "nlp_uncertainty_zoo.utils.__init__", "type": "module", "doc": "<p></p>\n"}, {"fullname": "nlp_uncertainty_zoo.utils.custom_types", "modulename": "nlp_uncertainty_zoo.utils.custom_types", "type": "module", "doc": "<p>Define custom types for this project.</p>\n"}, {"fullname": "nlp_uncertainty_zoo.utils.data", "modulename": "nlp_uncertainty_zoo.utils.data", "type": "module", "doc": "<p>Module to implement data reading and batching functionalities.</p>\n"}, {"fullname": "nlp_uncertainty_zoo.utils.data.ModifiedDataCollatorForLanguageModeling", "modulename": "nlp_uncertainty_zoo.utils.data", "qualname": "ModifiedDataCollatorForLanguageModeling", "type": "class", "doc": "<p>Modified version of the DataCollatorForLanguageModelling. The only change introduced is to the __call__ function,\nwhere an offset between input_ids and labels for next token prediction language modelling in order to be consistent\nwith the rest of the code base.</p>\n", "bases": "transformers.data.data_collator.DataCollatorForLanguageModeling"}, {"fullname": "nlp_uncertainty_zoo.utils.data.DatasetBuilder", "modulename": "nlp_uncertainty_zoo.utils.data", "qualname": "DatasetBuilder", "type": "class", "doc": "<p>Abstract dataset builder class used to create a variety of different dataset types, including sequence prediction,\ntoken prediction, next-token-prediction language modelling and masked language modelling.</p>\n", "bases": "abc.ABC"}, {"fullname": "nlp_uncertainty_zoo.utils.data.DatasetBuilder.__init__", "modulename": "nlp_uncertainty_zoo.utils.data", "qualname": "DatasetBuilder.__init__", "type": "function", "doc": "<p>Initialize a DatasetBuilder.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>name</strong> (str):\nName of the final dataset.</li>\n<li><strong>data_dir</strong> (str):\nDirectory in which data splits are located.</li>\n<li><strong>splits</strong> (Dict[str, Any]):\nDictionary pointing to the files containing the training, validation and test split.</li>\n<li><strong>type_</strong> (str):\nString that further specifies the type of dataset being built (see LanguageModellingDatasetBuilder and\nClassificationDatasetBuilder for more detail).</li>\n<li><strong>tokenizer</strong> (PreTrainedTokenizerBase):\nPre-trained tokenizer.</li>\n<li><strong>max_length</strong> (int):\nMaximum sequence length.</li>\n<li><strong>sampler_class</strong> (Optional[Sampler]):\nSampler class used to (sub-)sample the dataset.</li>\n<li><strong>sampler_kwargs</strong> (Optional[SamplerKwargs]):\nKeyword arguments to initialize the sampler.</li>\n<li><strong>num_jobs</strong> (Optional[int]):\nNumber of jobs used to build the dataset (on CPU). Default is 1.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">data_dir</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">splits</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">type_</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">tokenizer</span><span class=\"p\">:</span> <span class=\"n\">transformers</span><span class=\"o\">.</span><span class=\"n\">tokenization_utils_base</span><span class=\"o\">.</span><span class=\"n\">PreTrainedTokenizerBase</span>,</span><span class=\"param\">\t<span class=\"n\">max_length</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">sampler_class</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Type</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">sampler_kwargs</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">],</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]],</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">num_jobs</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mi\">1</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.utils.data.DatasetBuilder.build", "modulename": "nlp_uncertainty_zoo.utils.data", "qualname": "DatasetBuilder.build", "type": "function", "doc": "<p>Build a dataset.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>batch_size</strong> (int):\nThe desired batch size.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>Dict[str, DataLoader]</strong>: Dictionary of DataLoaders for every given split.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">dataloader_kwargs</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataloader</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.utils.data.LanguageModellingDatasetBuilder", "modulename": "nlp_uncertainty_zoo.utils.data", "qualname": "LanguageModellingDatasetBuilder", "type": "class", "doc": "<p>DatasetBuilder for language modelling datasets. This includes \"classic\" language modelling (aka next token\nprediction) as well as masked language modelling.</p>\n", "bases": "DatasetBuilder"}, {"fullname": "nlp_uncertainty_zoo.utils.data.LanguageModellingDatasetBuilder.build", "modulename": "nlp_uncertainty_zoo.utils.data", "qualname": "LanguageModellingDatasetBuilder.build", "type": "function", "doc": "<p>Build a language modelling dataset.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>batch_size</strong> (int):\nThe desired batch size.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>Dict[str, DataLoader]</strong>: Dictionary of DataLoaders for every given split.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">dataloader_kwargs</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataloader</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.utils.data.ClassificationDatasetBuilder", "modulename": "nlp_uncertainty_zoo.utils.data", "qualname": "ClassificationDatasetBuilder", "type": "class", "doc": "<p>DatasetBuilder for classification datasets. This includes sequence classification and token classification /\nsequence labelling.</p>\n", "bases": "DatasetBuilder"}, {"fullname": "nlp_uncertainty_zoo.utils.data.ClassificationDatasetBuilder.build", "modulename": "nlp_uncertainty_zoo.utils.data", "qualname": "ClassificationDatasetBuilder.build", "type": "function", "doc": "<p>Build a language modelling dataset.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>batch_size</strong> (int):\nThe desired batch size.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>Dict[str, DataLoader]</strong>: Dictionary of DataLoaders for every given split.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"o\">**</span><span class=\"n\">dataloader_kwargs</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Any</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataloader</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.utils.metrics", "modulename": "nlp_uncertainty_zoo.utils.metrics", "type": "module", "doc": "<p>Define some uncertainty metrics for neural discriminators. These usually operate on the predicted logits unless\nspecified otherwise.</p>\n"}, {"fullname": "nlp_uncertainty_zoo.utils.metrics.max_prob", "modulename": "nlp_uncertainty_zoo.utils.metrics", "qualname": "max_prob", "type": "function", "doc": "<p>Compute the maximum softmax probability baseline by [1] for a tensor of batch_size x seq_len x output_size.\nBecause we want a high value when uncertainty is high, we actually compute 1 - max. prob.</p>\n\n<p>[1] <a href=\"https://arxiv.org/pdf/1610.02136.pdf\">https://arxiv.org/pdf/1610.02136.pdf</a></p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>logits</strong> (torch.FloatTensor):\nLogits of the current batch.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Max. prob. values for the current batch.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">logits</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.utils.metrics.softmax_gap", "modulename": "nlp_uncertainty_zoo.utils.metrics", "qualname": "softmax_gap", "type": "function", "doc": "<p>Compute softmax gap by [2] for a tensor of batch_size x seq_len x output_size.</p>\n\n<p>[2] <a href=\"https://arxiv.org/pdf/1811.00908.pdf\">https://arxiv.org/pdf/1811.00908.pdf</a></p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>logits</strong> (torch.FloatTensor):\nLogits of the current batch.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Softmax gap.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">logits</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.utils.metrics.predictive_entropy", "modulename": "nlp_uncertainty_zoo.utils.metrics", "qualname": "predictive_entropy", "type": "function", "doc": "<p>Compute predictive entropy for a tensor of batch_size x seq_len x output_size.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>logits</strong> (torch.FloatTensor):\nLogits of the current batch.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Predictive entropy for the current batch.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">logits</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>, </span><span class=\"param\"><span class=\"n\">eps</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-05</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.utils.metrics.dempster_shafer", "modulename": "nlp_uncertainty_zoo.utils.metrics", "qualname": "dempster_shafer", "type": "function", "doc": "<p>Compute the dempster-shafer metric [2] for a tensor of batch_size x seq_len x output_size.</p>\n\n<p>[2] <a href=\"https://proceedings.neurips.cc/paper/2018/file/a981f2b708044d6fb4a71a1463242520-Paper.pdf\">https://proceedings.neurips.cc/paper/2018/file/a981f2b708044d6fb4a71a1463242520-Paper.pdf</a></p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>logits</strong> (torch.FloatTensor):\nLogits of the current batch.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Dempster-shafer metric for the current batch.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">logits</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.utils.metrics.variance", "modulename": "nlp_uncertainty_zoo.utils.metrics", "qualname": "variance", "type": "function", "doc": "<p>Compute the variance in predictions given a number of predictions. Thus, this metric expects\na logit tensor of size batch_size x num_predictions x seq_len x output_size.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>logits</strong> (torch.FloatTensor):\nLogits of the current batch.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Variance in predictions for the current batch.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">logits</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.utils.metrics.mutual_information", "modulename": "nlp_uncertainty_zoo.utils.metrics", "qualname": "mutual_information", "type": "function", "doc": "<p>Compute the mutual information as defined in [3] given a number of predictions. Thus, this metric expects\na logit tensor of size batch_size x num_predictions x seq_len x output_size.</p>\n\n<p>[3] <a href=\"https://arxiv.org/pdf/1803.08533.pdf\">https://arxiv.org/pdf/1803.08533.pdf</a></p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>logits</strong> (torch.FloatTensor):\nLogits of the current batch.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>torch.FloatTensor</strong>: Mutual information for the current batch.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">logits</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>, </span><span class=\"param\"><span class=\"n\">eps</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-05</span></span><span class=\"return-annotation\">) -> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">FloatTensor</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.utils.samplers", "modulename": "nlp_uncertainty_zoo.utils.samplers", "type": "module", "doc": "<p>Sampler used to sub-sample different types of datasets. In each class, some statistics about the distribution of inputs\nis built, and then indices of instances from the dataset are subs-ampled based on these statistics.</p>\n"}, {"fullname": "nlp_uncertainty_zoo.utils.samplers.create_probs_from_dict", "modulename": "nlp_uncertainty_zoo.utils.samplers", "qualname": "create_probs_from_dict", "type": "function", "doc": "<p>Auxiliary function creating a numpy array containing a categorical distribution over integers from\na dictionary of frequencies.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>freq_dict</strong> (Dict[int, int]):\nDictionary mapping from class labels to frequencies.</li>\n<li><strong>max_label</strong> (Optional[int]):\nMaximum value of a class label aka number of classes (minus 1). If None, tyis is based on the maximum valued\nkey in freq_dict.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>np.array</strong>: Distribution over class labels as a numpy array.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">freq_dict</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">max_label</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"o\">&lt;</span><span class=\"n\">built</span><span class=\"o\">-</span><span class=\"ow\">in</span> <span class=\"n\">function</span> <span class=\"n\">array</span><span class=\"o\">&gt;</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.utils.samplers.merge_freq_dicts", "modulename": "nlp_uncertainty_zoo.utils.samplers", "qualname": "merge_freq_dicts", "type": "function", "doc": "<p>Merge two dictionaries of frequencies. Used for creating data statistics before sub-sampling, where statistics for\neach instance are collected via different jobs and then merged.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>freqs_a</strong> (Dict[int, int]):\nFirst frequency dictionary.</li>\n<li><strong>freqs_b</strong> (Dict[int, int]):\nSecond frequency dictionary.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>Dict[int, int]</strong>: New frequency dictionary.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">freqs_a</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">]</span>, </span><span class=\"param\"><span class=\"n\">freqs_b</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">]</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.utils.samplers.merge_instance_dicts", "modulename": "nlp_uncertainty_zoo.utils.samplers", "qualname": "merge_instance_dicts", "type": "function", "doc": "<p>Merge two dictionaries of instances lights, where inputs are grouped by a common characteristic, e.g. length. Used\nfor creating data statistics before sub-sampling, where statistics for each instance are collected via different\njobs and then merged.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>lengths_a</strong> (Dict[int, List[int]]):\nFirst instance dictionary.</li>\n<li><strong>lengths_b</strong> (Dict[int, List[int]]):\nSecond instance dictionary.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>Dict[int, List[int]]</strong>: New instance dictionary.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">lengths_a</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span>,</span><span class=\"param\">\t<span class=\"n\">lengths_b</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">]]</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.utils.samplers.Subsampler", "modulename": "nlp_uncertainty_zoo.utils.samplers", "qualname": "Subsampler", "type": "class", "doc": "<p>Abstract base class of any sampler that sub-samples a dataset to a given target size.</p>\n", "bases": "typing.Generic[+T_co]"}, {"fullname": "nlp_uncertainty_zoo.utils.samplers.Subsampler.__init__", "modulename": "nlp_uncertainty_zoo.utils.samplers", "qualname": "Subsampler.__init__", "type": "function", "doc": "<p>Initialize a sub-sampler.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>data_source</strong> (Sized):\nIterable of data corresponding to a split. Usually is a list of dicts, containing input ids, attention masks\nand labels for each instance.</li>\n<li><strong>target_size</strong> (int):\nNumber of instances that should be contained in the sub-sampled data set.</li>\n<li><strong>num_jobs</strong> (int):\nNumber of jobs used to process data before sampling.</li>\n<li><strong>seed</strong> (Optional[int]):\nSeed set for reproducibility.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">data_source</span><span class=\"p\">:</span> <span class=\"n\">Sized</span>,</span><span class=\"param\">\t<span class=\"n\">target_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_jobs</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">seed</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.utils.samplers.LanguageModellingSampler", "modulename": "nlp_uncertainty_zoo.utils.samplers", "qualname": "LanguageModellingSampler", "type": "class", "doc": "<p>Sampler specific to language modelling. The sub-sampling strategy here is to approximately maintain the same\ndistribution of sentence lengths as in the original corpus, and to maintain contiguous paragraphs of text spanning\nmultiple sentences.</p>\n", "bases": "typing.Generic[+T_co]"}, {"fullname": "nlp_uncertainty_zoo.utils.samplers.LanguageModellingSampler.__init__", "modulename": "nlp_uncertainty_zoo.utils.samplers", "qualname": "LanguageModellingSampler.__init__", "type": "function", "doc": "<p>Initialize a sub-sampler for language modelling data sets.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>data_source</strong> (Sized):\nIterable of data corresponding to a split. Usually is a list of dicts, containing input ids, attention masks\nand labels for each instance.</li>\n<li><strong>target_size</strong> (int):\nNumber of instances that should be contained in the sub-sampled data set.</li>\n<li><strong>sample_range</strong> (Tuple[int, int]):\nLength of paragraphs that are sampled from the corpus. sample_range determines the ranges from which the\nlength is sampled uniformly.</li>\n<li><strong>num_jobs</strong> (int):\nNumber of jobs used to process data before sampling.</li>\n<li><strong>seed</strong> (Optional[int]):\nSeed set for reproducibility.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">data_source</span><span class=\"p\">:</span> <span class=\"n\">Sized</span>,</span><span class=\"param\">\t<span class=\"n\">target_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">sample_range</span><span class=\"p\">:</span> <span class=\"n\">Tuple</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"nb\">int</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">num_jobs</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">seed</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.utils.samplers.SequenceClassificationSampler", "modulename": "nlp_uncertainty_zoo.utils.samplers", "qualname": "SequenceClassificationSampler", "type": "class", "doc": "<p>Sampler specific to sequence classification. The strategy here is to approximately maintain the same class\ndistribution as in the original corpus, and to a lesser extent the same sequence length distribution.</p>\n", "bases": "typing.Generic[+T_co]"}, {"fullname": "nlp_uncertainty_zoo.utils.samplers.SequenceClassificationSampler.__init__", "modulename": "nlp_uncertainty_zoo.utils.samplers", "qualname": "SequenceClassificationSampler.__init__", "type": "function", "doc": "<p>Initialize a sub-sampler for sequence classification tasks.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>data_source</strong> (Sized):\nIterable of data corresponding to a split. Usually is a list of dicts, containing input ids, attention masks\nand labels for each instance.</li>\n<li><strong>target_size</strong> (int):\nNumber of instances that should be contained in the sub-sampled data set.</li>\n<li><strong>num_jobs</strong> (int):\nNumber of jobs used to process data before sampling.</li>\n<li><strong>seed</strong> (Optional[int]):\nSeed set for reproducibility.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">data_source</span><span class=\"p\">:</span> <span class=\"n\">Sized</span>,</span><span class=\"param\">\t<span class=\"n\">target_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_jobs</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">seed</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.utils.samplers.TokenClassificationSampler", "modulename": "nlp_uncertainty_zoo.utils.samplers", "qualname": "TokenClassificationSampler", "type": "class", "doc": "<p>Sampler specific to sequence classification. The strategy here is to approximately maintain the same class\ndistribution as in the original corpus, and to a lesser extent the same sequence length distribution. Compared to\nthe SequenceClassificationSampler, all labels of a sequence are considered.</p>\n", "bases": "typing.Generic[+T_co]"}, {"fullname": "nlp_uncertainty_zoo.utils.samplers.TokenClassificationSampler.__init__", "modulename": "nlp_uncertainty_zoo.utils.samplers", "qualname": "TokenClassificationSampler.__init__", "type": "function", "doc": "<p>Initialize a sub-sampler for token classification tasks.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>data_source</strong> (Sized):\nIterable of data corresponding to a split. Usually is a list of dicts, containing input ids, attention masks\nand labels for each instance.</li>\n<li><strong>target_size</strong> (int):\nNumber of instances that should be contained in the sub-sampled data set.</li>\n<li><strong>ignore_label</strong> (int):\nDetermine label that should be ignored when computing input statistics used for sampling. Default is -100.</li>\n<li><strong>num_jobs</strong> (int):\nNumber of jobs used to process data before sampling.</li>\n<li><strong>seed</strong> (Optional[int]):\nSeed set for reproducibility.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">data_source</span><span class=\"p\">:</span> <span class=\"n\">Sized</span>,</span><span class=\"param\">\t<span class=\"n\">target_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">ignore_label</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"o\">-</span><span class=\"mi\">100</span>,</span><span class=\"param\">\t<span class=\"n\">num_jobs</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">seed</span><span class=\"p\">:</span> <span class=\"n\">Union</span><span class=\"p\">[</span><span class=\"nb\">int</span><span class=\"p\">,</span> <span class=\"n\">NoneType</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "nlp_uncertainty_zoo.utils.task_eval", "modulename": "nlp_uncertainty_zoo.utils.task_eval", "type": "module", "doc": "<p>Implementation of evaluation logic.</p>\n"}, {"fullname": "nlp_uncertainty_zoo.utils.task_eval.evaluate", "modulename": "nlp_uncertainty_zoo.utils.task_eval", "qualname": "evaluate", "type": "function", "doc": "<p>Evaluate a model and save predictions (if applicable).</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>model</strong> (Model):\nModel to be evaluated.</li>\n<li><strong>eval_split</strong> (DataSplit):\nData split the model is being evaluated on.</li>\n<li><strong>tokenizer</strong> (PreTrainedTokenizerBase):\nTokenizer of the evaluated model.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>Dict[str, float]</strong>: Return score on test set.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model</span>,</span><span class=\"param\">\t<span class=\"n\">eval_split</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataloader</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span>,</span><span class=\"param\">\t<span class=\"n\">tokenizer</span><span class=\"p\">:</span> <span class=\"n\">transformers</span><span class=\"o\">.</span><span class=\"n\">tokenization_utils_base</span><span class=\"o\">.</span><span class=\"n\">PreTrainedTokenizerBase</span></span><span class=\"return-annotation\">) -> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"nb\">float</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.utils.uncertainty_eval", "modulename": "nlp_uncertainty_zoo.utils.uncertainty_eval", "type": "module", "doc": "<p>Module to implement different metrics the quality of uncertainty metrics.</p>\n"}, {"fullname": "nlp_uncertainty_zoo.utils.uncertainty_eval.aupr", "modulename": "nlp_uncertainty_zoo.utils.uncertainty_eval", "qualname": "aupr", "type": "function", "doc": "<p>Return the area under the precision-recall curve for a pseudo binary classification task, where in- and\nout-of-distribution samples correspond to two different classes, which are differentiated using uncertainty scores.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>y_true</strong> (np.array):\nTrue labels, where 1 corresponds to in- and 0 to out-of-distribution.</li>\n<li><strong>y_pred</strong> (np.array):\nUncertainty scores as predictions to distinguish the two classes.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>float</strong>: Area under the precision-recall curve.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">y_true</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">built</span><span class=\"o\">-</span><span class=\"ow\">in</span> <span class=\"n\">function</span> <span class=\"n\">array</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">y_pred</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">built</span><span class=\"o\">-</span><span class=\"ow\">in</span> <span class=\"n\">function</span> <span class=\"n\">array</span><span class=\"o\">&gt;</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">float</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.utils.uncertainty_eval.auroc", "modulename": "nlp_uncertainty_zoo.utils.uncertainty_eval", "qualname": "auroc", "type": "function", "doc": "<p>Return the area under the receiver-operator characteristic for a pseudo binary classification task, where in- and\nout-of-distribution samples correspond to two different classes, which are differentiated using uncertainty scores.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>y_true</strong> (np.array):\nTrue labels, where 1 corresponds to in- and 0 to out-of-distribution.</li>\n<li><strong>y_pred</strong> (np.array):\nUncertainty scores as predictions to distinguish the two classes.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>float</strong>: Area under the receiver-operator characteristic.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">y_true</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">built</span><span class=\"o\">-</span><span class=\"ow\">in</span> <span class=\"n\">function</span> <span class=\"n\">array</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">y_pred</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">built</span><span class=\"o\">-</span><span class=\"ow\">in</span> <span class=\"n\">function</span> <span class=\"n\">array</span><span class=\"o\">&gt;</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">float</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.utils.uncertainty_eval.kendalls_tau", "modulename": "nlp_uncertainty_zoo.utils.uncertainty_eval", "qualname": "kendalls_tau", "type": "function", "doc": "<p>Compute Kendall's tau for a list of losses and uncertainties for a set of inputs. If the two lists are concordant,\ni.e. the points with the highest uncertainty incur the highest loss, Kendall's tau is 1. If they are completely\ndiscordant, it is -1.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>losses</strong> (np.array):\nList of losses for a set of points.</li>\n<li><strong>uncertainties</strong> (np.array):\nList of uncertainty for a set of points.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>float</strong>: Kendall's tau, between -1 and 1.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">losses</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">built</span><span class=\"o\">-</span><span class=\"ow\">in</span> <span class=\"n\">function</span> <span class=\"n\">array</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">uncertainties</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">built</span><span class=\"o\">-</span><span class=\"ow\">in</span> <span class=\"n\">function</span> <span class=\"n\">array</span><span class=\"o\">&gt;</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">float</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.utils.uncertainty_eval.ece", "modulename": "nlp_uncertainty_zoo.utils.uncertainty_eval", "qualname": "ece", "type": "function", "doc": "<p>Calculate the Expected Calibration Error: for each bin, the absolute difference between\nthe mean fraction of positives and the average predicted probability is taken. The ECE is\nthe weighed mean of these differences.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>y</strong> (np.ndarray):\nThe true labels.</li>\n<li><strong>y_pred</strong> (np.ndarray):\nThe predicted probabilities</li>\n<li><strong>n_bins</strong> (int):\nThe number of bins to use.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>ece</strong> (float):\nThe expected calibration error.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">y_true</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">built</span><span class=\"o\">-</span><span class=\"ow\">in</span> <span class=\"n\">function</span> <span class=\"n\">array</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">y_pred</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">built</span><span class=\"o\">-</span><span class=\"ow\">in</span> <span class=\"n\">function</span> <span class=\"n\">array</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">n_bins</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">10</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">float</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.utils.uncertainty_eval.sce", "modulename": "nlp_uncertainty_zoo.utils.uncertainty_eval", "qualname": "sce", "type": "function", "doc": "<p>Measure the Static Calibration Error (SCE) by [2], an extension to the Expected Calibration Error to multiple\nclasses.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>y_true</strong> (np.array):\nTrue labels for each input.</li>\n<li><strong>y_pred</strong> (np.array):\nCategorical probability distribution for each input.</li>\n<li><strong>num_bins</strong> (int):\nNumber of bins. Default is 10.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>float</strong>: Static Calibration Error.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">y_true</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">built</span><span class=\"o\">-</span><span class=\"ow\">in</span> <span class=\"n\">function</span> <span class=\"n\">array</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">y_pred</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">built</span><span class=\"o\">-</span><span class=\"ow\">in</span> <span class=\"n\">function</span> <span class=\"n\">array</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">num_bins</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">10</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">float</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.utils.uncertainty_eval.ace", "modulename": "nlp_uncertainty_zoo.utils.uncertainty_eval", "qualname": "ace", "type": "function", "doc": "<p>Measure the Adaptive Calibration Error (ACE) by [2], an version of the static calibration error that uses ranges\n instead of bins. Every range contains the same number of predictions.</p>\n\n<p>Parameters</p>\n\n<hr />\n\n<p>y_true: np.array\n     True labels for each input.\n y_pred: np.array\n     Categorical probability distribution for each input.\n num_ranges: int\n     Number of ranges. Default is 10.</p>\n\n<p>Returns</p>\n\n<hr />\n\n<p>float\n     Adaptive Calibration Error.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">y_true</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">built</span><span class=\"o\">-</span><span class=\"ow\">in</span> <span class=\"n\">function</span> <span class=\"n\">array</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">y_pred</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">built</span><span class=\"o\">-</span><span class=\"ow\">in</span> <span class=\"n\">function</span> <span class=\"n\">array</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">num_ranges</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">10</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">float</span>:</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.utils.uncertainty_eval.coverage_percentage", "modulename": "nlp_uncertainty_zoo.utils.uncertainty_eval", "qualname": "coverage_percentage", "type": "function", "doc": "<p>Return the percentage of times the true prediction was contained in the 1 - alpha prediction set. Based on the work\nby [3].</p>\n\n<p>[3] Kompa, Benjamin, Jasper Snoek, and Andrew L. Beam. \"Empirical frequentist coverage of deep learning uncertainty\nquantification procedures.\" Entropy 23.12 (2021): 1608.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>y_true</strong> (np.array):\nTrue labels for each input.</li>\n<li><strong>y_pred</strong> (np.array):\nCategorical probability distribution for each input.</li>\n<li><strong>alpha</strong> (float):\nProbability mass threshold.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>float</strong>: Coverage percentage.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">y_true</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">built</span><span class=\"o\">-</span><span class=\"ow\">in</span> <span class=\"n\">function</span> <span class=\"n\">array</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">y_pred</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">built</span><span class=\"o\">-</span><span class=\"ow\">in</span> <span class=\"n\">function</span> <span class=\"n\">array</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">alpha</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.05</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "nlp_uncertainty_zoo.utils.uncertainty_eval.coverage_width", "modulename": "nlp_uncertainty_zoo.utils.uncertainty_eval", "qualname": "coverage_width", "type": "function", "doc": "<p>Return the width of the 1 - alpha prediction set. Based on the work by [3].</p>\n\n<p>[3] Kompa, Benjamin, Jasper Snoek, and Andrew L. Beam. \"Empirical frequentist coverage of deep learning uncertainty\nquantification procedures.\" Entropy 23.12 (2021): 1608.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>y_pred</strong> (np.array):\nCategorical probability distribution for each input.</li>\n<li><strong>alpha</strong> (float):\nProbability mass threshold.</li>\n<li><strong>eps</strong> (float):\nSmall number to avoid floating point precision problems.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>float</strong>: Average prediction set width.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">y_pred</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">built</span><span class=\"o\">-</span><span class=\"ow\">in</span> <span class=\"n\">function</span> <span class=\"n\">array</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">alpha</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">0.05</span>,</span><span class=\"param\">\t<span class=\"n\">eps</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-08</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}];

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&_'"=,()]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.pipeline.remove(elasticlunr.stemmer);
            this.pipeline.remove(elasticlunr.stopWordFilter);
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();