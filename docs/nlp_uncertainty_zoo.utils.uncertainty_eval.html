<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>nlp_uncertainty_zoo.utils.uncertainty_eval &#8212; nlp-uncertainty-zoo 0.9.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/bootstrap-sphinx.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="nlp_uncertainty_zoo.utils.task_eval" href="nlp_uncertainty_zoo.utils.task_eval.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="_static/js/jquery-1.12.4.min.js"></script>
<script type="text/javascript" src="_static/js/jquery-fix.js"></script>
<script type="text/javascript" src="_static/bootstrap-3.4.1/js/bootstrap.min.js"></script>
<script type="text/javascript" src="_static/bootstrap-sphinx.js"></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html">
          nlp-uncertainty-zoo</a>
        <span class="navbar-text navbar-version pull-left"><b>0.9.0</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.html">nlp_uncertainty_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.html">nlp_uncertainty_zoo.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.html#the-module-class">The <cite>Module</cite> class</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.html#the-model-class">The <cite>Model</cite> class</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.html#module-nlp_uncertainty_zoo.models">Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.bayesian_lstm.html">Bayesian LSTM</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.bayesian_lstm.html#bayesian-lstm-module-documentation">Bayesian LSTM Module Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.bert.html">BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.bert.html#module-nlp_uncertainty_zoo.models.bert">BERT Module Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.ddu_transformer.html">DDU Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.ddu_transformer.html#module-nlp_uncertainty_zoo.models.ddu_transformer">DDU Transformer Module Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.dpp_transformer.html">DPP Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.dpp_transformer.html#module-nlp_uncertainty_zoo.models.dpp_transformer">DPP Transformer Module Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.lstm.html">nlp_uncertainty_zoo.models.lstm</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.lstm_ensemble.html">nlp_uncertainty_zoo.models.lstm_ensemble</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.model.html">nlp_uncertainty_zoo.models.model</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.sngp_transformer.html">nlp_uncertainty_zoo.models.sngp_transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.spectral.html">nlp_uncertainty_zoo.models.spectral</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.st_tau_lstm.html">nlp_uncertainty_zoo.models.st_tau_lstm</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.transformer.html">nlp_uncertainty_zoo.models.transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.st_tau_lstm.html">nlp_uncertainty_zoo.models.st_tau_lstm</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.transformer.html">nlp_uncertainty_zoo.models.transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.variational_lstm.html">nlp_uncertainty_zoo.models.variational_lstm</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.variational_transformer.html">nlp_uncertainty_zoo.models.variational_transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.utils.html">nlp_uncertainty_zoo.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.utils.custom_types.html">nlp_uncertainty_zoo.utils.custom_types</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.utils.data.html">nlp_uncertainty_zoo.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.utils.metrics.html">nlp_uncertainty_zoo.utils.metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.utils.samplers.html">nlp_uncertainty_zoo.utils.samplers</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.utils.task_eval.html">nlp_uncertainty_zoo.utils.task_eval</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">nlp_uncertainty_zoo.utils.uncertainty_eval</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">nlp_uncertainty_zoo.utils.uncertainty_eval</a><ul>
<li><a class="reference internal" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.ace"><code class="docutils literal notranslate"><span class="pre">ace()</span></code></a></li>
<li><a class="reference internal" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.aupr"><code class="docutils literal notranslate"><span class="pre">aupr()</span></code></a></li>
<li><a class="reference internal" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.auroc"><code class="docutils literal notranslate"><span class="pre">auroc()</span></code></a></li>
<li><a class="reference internal" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.average_precision_score"><code class="docutils literal notranslate"><span class="pre">average_precision_score()</span></code></a></li>
<li><a class="reference internal" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.coverage_percentage"><code class="docutils literal notranslate"><span class="pre">coverage_percentage()</span></code></a></li>
<li><a class="reference internal" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.coverage_width"><code class="docutils literal notranslate"><span class="pre">coverage_width()</span></code></a></li>
<li><a class="reference internal" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.ece"><code class="docutils literal notranslate"><span class="pre">ece()</span></code></a></li>
<li><a class="reference internal" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.kendalls_tau"><code class="docutils literal notranslate"><span class="pre">kendalls_tau()</span></code></a></li>
<li><a class="reference internal" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.kendalltau"><code class="docutils literal notranslate"><span class="pre">kendalltau()</span></code></a></li>
<li><a class="reference internal" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.roc_auc_score"><code class="docutils literal notranslate"><span class="pre">roc_auc_score()</span></code></a></li>
<li><a class="reference internal" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.sce"><code class="docutils literal notranslate"><span class="pre">sce()</span></code></a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
  <li>
    <a href="nlp_uncertainty_zoo.utils.task_eval.html" title="Previous Chapter: nlp_uncertainty_zoo.utils.task_eval"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; nlp_uncertain...</span>
    </a>
  </li>
              
            
            
            
            
              <li class="hidden-sm">
<div id="sourcelink">
  <a href="_sources/nlp_uncertainty_zoo.utils.uncertainty_eval.rst.txt"
     rel="nofollow">Source</a>
</div></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <section id="nlp-uncertainty-zoo-utils-uncertainty-eval">
<h1>nlp_uncertainty_zoo.utils.uncertainty_eval<a class="headerlink" href="#nlp-uncertainty-zoo-utils-uncertainty-eval" title="Permalink to this heading">¶</a></h1>
<span class="target" id="module-nlp_uncertainty_zoo.utils.uncertainty_eval"></span><p>Module to implement different metrics the quality of uncertainty metrics.</p>
<dl class="py function">
<dt class="sig sig-object py" id="nlp_uncertainty_zoo.utils.uncertainty_eval.ace">
<span class="sig-prename descclassname"><span class="pre">nlp_uncertainty_zoo.utils.uncertainty_eval.</span></span><span class="sig-name descname"><span class="pre">ace</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_ranges</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.ace" title="Permalink to this definition">¶</a></dt>
<dd><blockquote>
<div><p>Measure the Adaptive Calibration Error (ACE) by [2], an version of the static calibration error that uses ranges
instead of bins. Every range contains the same number of predictions.</p>
</div></blockquote>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>y_true: np.array</strong></dt><dd><blockquote>
<div><p>True labels for each input.</p>
</div></blockquote>
<dl class="simple">
<dt>y_pred: np.array</dt><dd><p>Categorical probability distribution for each input.</p>
</dd>
<dt>num_ranges: int</dt><dd><p>Number of ranges. Default is 10.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>float</dt><dd><p>Adaptive Calibration Error.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nlp_uncertainty_zoo.utils.uncertainty_eval.aupr">
<span class="sig-prename descclassname"><span class="pre">nlp_uncertainty_zoo.utils.uncertainty_eval.</span></span><span class="sig-name descname"><span class="pre">aupr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">array</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.aupr" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the area under the precision-recall curve for a pseudo binary classification task, where in- and
out-of-distribution samples correspond to two different classes, which are differentiated using uncertainty scores.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>y_true: np.array</strong></dt><dd><p>True labels, where 1 corresponds to in- and 0 to out-of-distribution.</p>
</dd>
<dt><strong>y_pred: np.array</strong></dt><dd><p>Uncertainty scores as predictions to distinguish the two classes.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>float</dt><dd><p>Area under the precision-recall curve.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nlp_uncertainty_zoo.utils.uncertainty_eval.auroc">
<span class="sig-prename descclassname"><span class="pre">nlp_uncertainty_zoo.utils.uncertainty_eval.</span></span><span class="sig-name descname"><span class="pre">auroc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">array</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.auroc" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the area under the receiver-operator characteristic for a pseudo binary classification task, where in- and
out-of-distribution samples correspond to two different classes, which are differentiated using uncertainty scores.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>y_true: np.array</strong></dt><dd><p>True labels, where 1 corresponds to in- and 0 to out-of-distribution.</p>
</dd>
<dt><strong>y_pred: np.array</strong></dt><dd><p>Uncertainty scores as predictions to distinguish the two classes.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>float</dt><dd><p>Area under the receiver-operator characteristic.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nlp_uncertainty_zoo.utils.uncertainty_eval.average_precision_score">
<span class="sig-prename descclassname"><span class="pre">nlp_uncertainty_zoo.utils.uncertainty_eval.</span></span><span class="sig-name descname"><span class="pre">average_precision_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_score</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">average</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'macro'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pos_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.average_precision_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute average precision (AP) from prediction scores.</p>
<p>AP summarizes a precision-recall curve as the weighted mean of precisions
achieved at each threshold, with the increase in recall from the previous
threshold used as the weight:</p>
<div class="math notranslate nohighlight">
\[\text{AP} = \sum_n (R_n - R_{n-1}) P_n\]</div>
<p>where <span class="math notranslate nohighlight">\(P_n\)</span> and <span class="math notranslate nohighlight">\(R_n\)</span> are the precision and recall at the nth
threshold <a class="reference internal" href="#r53e8459717ec-1" id="id1">[1]</a>. This implementation is not interpolated and is different
from computing the area under the precision-recall curve with the
trapezoidal rule, which uses linear interpolation and can be too
optimistic.</p>
<p>Note: this implementation is restricted to the binary classification task
or multilabel classification task.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>y_true</strong><span class="classifier">ndarray of shape (n_samples,) or (n_samples, n_classes)</span></dt><dd><p>True binary labels or binary label indicators.</p>
</dd>
<dt><strong>y_score</strong><span class="classifier">ndarray of shape (n_samples,) or (n_samples, n_classes)</span></dt><dd><p>Target scores, can either be probability estimates of the positive
class, confidence values, or non-thresholded measure of decisions
(as returned by <span class="xref std std-term">decision_function</span> on some classifiers).</p>
</dd>
<dt><strong>average</strong><span class="classifier">{‘micro’, ‘samples’, ‘weighted’, ‘macro’} or None,             default=’macro’</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the scores for each class are returned. Otherwise,
this determines the type of averaging performed on the data:</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">'micro'</span></code>:</dt><dd><p>Calculate metrics globally by considering each element of the label
indicator matrix as a label.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">'macro'</span></code>:</dt><dd><p>Calculate metrics for each label, and find their unweighted
mean.  This does not take label imbalance into account.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">'weighted'</span></code>:</dt><dd><p>Calculate metrics for each label, and find their average, weighted
by support (the number of true instances for each label).</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">'samples'</span></code>:</dt><dd><p>Calculate metrics for each instance, and find their average.</p>
</dd>
</dl>
<p>Will be ignored when <code class="docutils literal notranslate"><span class="pre">y_true</span></code> is binary.</p>
</dd>
<dt><strong>pos_label</strong><span class="classifier">int or str, default=1</span></dt><dd><p>The label of the positive class. Only applied to binary <code class="docutils literal notranslate"><span class="pre">y_true</span></code>.
For multilabel-indicator <code class="docutils literal notranslate"><span class="pre">y_true</span></code>, <code class="docutils literal notranslate"><span class="pre">pos_label</span></code> is fixed to 1.</p>
</dd>
<dt><strong>sample_weight</strong><span class="classifier">array-like of shape (n_samples,), default=None</span></dt><dd><p>Sample weights.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>average_precision</strong><span class="classifier">float</span></dt><dd></dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.roc_auc_score" title="nlp_uncertainty_zoo.utils.uncertainty_eval.roc_auc_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">roc_auc_score</span></code></a></dt><dd><p>Compute the area under the ROC curve.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">precision_recall_curve</span></code></dt><dd><p>Compute precision-recall pairs for different probability thresholds.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.19: </span>Instead of linearly interpolating between operating points, precisions
are weighted by the change in recall since the last operating point.</p>
</div>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r53e8459717ec-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Information_retrieval&amp;oldid=793358396#Average_precision">Wikipedia entry for the Average precision</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">average_precision_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">average_precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>
<span class="go">0.83...</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nlp_uncertainty_zoo.utils.uncertainty_eval.coverage_percentage">
<span class="sig-prename descclassname"><span class="pre">nlp_uncertainty_zoo.utils.uncertainty_eval.</span></span><span class="sig-name descname"><span class="pre">coverage_percentage</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.05</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.coverage_percentage" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the percentage of times the true prediction was contained in the 1 - alpha prediction set. Based on the work
by [3].</p>
<p>[3] Kompa, Benjamin, Jasper Snoek, and Andrew L. Beam. “Empirical frequentist coverage of deep learning uncertainty
quantification procedures.” Entropy 23.12 (2021): 1608.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>y_true: np.array</strong></dt><dd><p>True labels for each input.</p>
</dd>
<dt><strong>y_pred: np.array</strong></dt><dd><p>Categorical probability distribution for each input.</p>
</dd>
<dt><strong>alpha: float</strong></dt><dd><p>Probability mass threshold.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>float</dt><dd><p>Coverage percentage.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nlp_uncertainty_zoo.utils.uncertainty_eval.coverage_width">
<span class="sig-prename descclassname"><span class="pre">nlp_uncertainty_zoo.utils.uncertainty_eval.</span></span><span class="sig-name descname"><span class="pre">coverage_width</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_pred</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-08</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.coverage_width" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the width of the 1 - alpha prediction set. Based on the work by [3].</p>
<p>[3] Kompa, Benjamin, Jasper Snoek, and Andrew L. Beam. “Empirical frequentist coverage of deep learning uncertainty
quantification procedures.” Entropy 23.12 (2021): 1608.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>y_pred: np.array</strong></dt><dd><p>Categorical probability distribution for each input.</p>
</dd>
<dt><strong>alpha: float</strong></dt><dd><p>Probability mass threshold.</p>
</dd>
<dt><strong>eps: float</strong></dt><dd><p>Small number to avoid floating point precision problems.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>float</dt><dd><p>Average prediction set width.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nlp_uncertainty_zoo.utils.uncertainty_eval.ece">
<span class="sig-prename descclassname"><span class="pre">nlp_uncertainty_zoo.utils.uncertainty_eval.</span></span><span class="sig-name descname"><span class="pre">ece</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_bins</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.ece" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the Expected Calibration Error: for each bin, the absolute difference between
the mean fraction of positives and the average predicted probability is taken. The ECE is
the weighed mean of these differences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>y: np.ndarray</strong></dt><dd><p>The true labels.</p>
</dd>
<dt><strong>y_pred: np.ndarray</strong></dt><dd><p>The predicted probabilities</p>
</dd>
<dt><strong>n_bins: int</strong></dt><dd><p>The number of bins to use.</p>
</dd>
<dt><strong>Returns</strong></dt><dd></dd>
<dt><strong>——-</strong></dt><dd></dd>
<dt><strong>ece: float</strong></dt><dd><p>The expected calibration error.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nlp_uncertainty_zoo.utils.uncertainty_eval.kendalls_tau">
<span class="sig-prename descclassname"><span class="pre">nlp_uncertainty_zoo.utils.uncertainty_eval.</span></span><span class="sig-name descname"><span class="pre">kendalls_tau</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">losses</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">uncertainties</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">array</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.kendalls_tau" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute Kendall’s tau for a list of losses and uncertainties for a set of inputs. If the two lists are concordant,
i.e. the points with the highest uncertainty incur the highest loss, Kendall’s tau is 1. If they are completely
discordant, it is -1.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>losses: np.array</strong></dt><dd><p>List of losses for a set of points.</p>
</dd>
<dt><strong>uncertainties: np.array</strong></dt><dd><p>List of uncertainty for a set of points.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>float</dt><dd><p>Kendall’s tau, between -1 and 1.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nlp_uncertainty_zoo.utils.uncertainty_eval.kendalltau">
<span class="sig-prename descclassname"><span class="pre">nlp_uncertainty_zoo.utils.uncertainty_eval.</span></span><span class="sig-name descname"><span class="pre">kendalltau</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_lexsort</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nan_policy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'propagate'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.kendalltau" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate Kendall’s tau, a correlation measure for ordinal data.</p>
<p>Kendall’s tau is a measure of the correspondence between two rankings.
Values close to 1 indicate strong agreement, values close to -1 indicate
strong disagreement.  This is the 1945 “tau-b” version of Kendall’s
tau <a class="reference internal" href="#r872329fac305-2" id="id3">[2]</a>, which can account for ties and which reduces to the 1938 “tau-a”
version <a class="reference internal" href="#r872329fac305-1" id="id4">[1]</a> in absence of ties.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>x, y</strong><span class="classifier">array_like</span></dt><dd><p>Arrays of rankings, of the same shape. If arrays are not 1-D, they will
be flattened to 1-D.</p>
</dd>
<dt><strong>initial_lexsort</strong><span class="classifier">bool, optional</span></dt><dd><p>Unused (deprecated).</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘raise’, ‘omit’}, optional</span></dt><dd><p>Defines how to handle when input contains nan.
The following options are available (default is ‘propagate’):</p>
<blockquote>
<div><ul class="simple">
<li><p>‘propagate’: returns nan</p></li>
<li><p>‘raise’: throws an error</p></li>
<li><p>‘omit’: performs the calculations ignoring nan values</p></li>
</ul>
</div></blockquote>
</dd>
<dt><strong>method</strong><span class="classifier">{‘auto’, ‘asymptotic’, ‘exact’}, optional</span></dt><dd><p>Defines which method is used to calculate the p-value <a class="reference internal" href="#r872329fac305-5" id="id5">[5]</a>.
The following options are available (default is ‘auto’):</p>
<blockquote>
<div><ul class="simple">
<li><p>‘auto’: selects the appropriate method based on a trade-off between
speed and accuracy</p></li>
<li><p>‘asymptotic’: uses a normal approximation valid for large samples</p></li>
<li><p>‘exact’: computes the exact p-value, but can only be used if no ties
are present</p></li>
</ul>
</div></blockquote>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>correlation</strong><span class="classifier">float</span></dt><dd><p>The tau statistic.</p>
</dd>
<dt><strong>pvalue</strong><span class="classifier">float</span></dt><dd><p>The two-sided p-value for a hypothesis test whose null hypothesis is
an absence of association, tau = 0.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">spearmanr</span></code></dt><dd><p>Calculates a Spearman rank-order correlation coefficient.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">theilslopes</span></code></dt><dd><p>Computes the Theil-Sen estimator for a set of points (x, y).</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">weightedtau</span></code></dt><dd><p>Computes a weighted version of Kendall’s tau.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>The definition of Kendall’s tau that is used is <a class="reference internal" href="#r872329fac305-2" id="id6">[2]</a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tau</span> <span class="o">=</span> <span class="p">(</span><span class="n">P</span> <span class="o">-</span> <span class="n">Q</span><span class="p">)</span> <span class="o">/</span> <span class="n">sqrt</span><span class="p">((</span><span class="n">P</span> <span class="o">+</span> <span class="n">Q</span> <span class="o">+</span> <span class="n">T</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">P</span> <span class="o">+</span> <span class="n">Q</span> <span class="o">+</span> <span class="n">U</span><span class="p">))</span>
</pre></div>
</div>
<p>where P is the number of concordant pairs, Q the number of discordant
pairs, T the number of ties only in <cite>x</cite>, and U the number of ties only in
<cite>y</cite>.  If a tie occurs for the same pair in both <cite>x</cite> and <cite>y</cite>, it is not
added to either T or U.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r872329fac305-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id4">1</a><span class="fn-bracket">]</span></span>
<p>Maurice G. Kendall, “A New Measure of Rank Correlation”, Biometrika
Vol. 30, No. 1/2, pp. 81-93, 1938.</p>
</div>
<div class="citation" id="r872329fac305-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id3">1</a>,<a role="doc-backlink" href="#id6">2</a>)</span>
<p>Maurice G. Kendall, “The treatment of ties in ranking problems”,
Biometrika Vol. 33, No. 3, pp. 239-251. 1945.</p>
</div>
<div class="citation" id="r872329fac305-3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></span>
<p>Gottfried E. Noether, “Elements of Nonparametric Statistics”, John
Wiley &amp; Sons, 1967.</p>
</div>
<div class="citation" id="r872329fac305-4" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></span>
<p>Peter M. Fenwick, “A new data structure for cumulative frequency
tables”, Software: Practice and Experience, Vol. 24, No. 3,
pp. 327-336, 1994.</p>
</div>
<div class="citation" id="r872329fac305-5" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id5">5</a><span class="fn-bracket">]</span></span>
<p>Maurice G. Kendall, “Rank Correlation Methods” (4th Edition),
Charles Griffin &amp; Co., 1970.</p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tau</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">kendalltau</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tau</span>
<span class="go">-0.47140452079103173</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p_value</span>
<span class="go">0.2827454599327748</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nlp_uncertainty_zoo.utils.uncertainty_eval.roc_auc_score">
<span class="sig-prename descclassname"><span class="pre">nlp_uncertainty_zoo.utils.uncertainty_eval.</span></span><span class="sig-name descname"><span class="pre">roc_auc_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_score</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">average</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'macro'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_fpr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multi_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'raise'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.roc_auc_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC)
from prediction scores.</p>
<p>Note: this implementation can be used with binary, multiclass and
multilabel classification, but some restrictions apply (see Parameters).</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>y_true</strong><span class="classifier">array-like of shape (n_samples,) or (n_samples, n_classes)</span></dt><dd><p>True labels or binary label indicators. The binary and multiclass cases
expect labels with shape (n_samples,) while the multilabel case expects
binary label indicators with shape (n_samples, n_classes).</p>
</dd>
<dt><strong>y_score</strong><span class="classifier">array-like of shape (n_samples,) or (n_samples, n_classes)</span></dt><dd><p>Target scores.</p>
<ul class="simple">
<li><p>In the binary case, it corresponds to an array of shape
<cite>(n_samples,)</cite>. Both probability estimates and non-thresholded
decision values can be provided. The probability estimates correspond
to the <strong>probability of the class with the greater label</strong>,
i.e. <cite>estimator.classes_[1]</cite> and thus
<cite>estimator.predict_proba(X, y)[:, 1]</cite>. The decision values
corresponds to the output of <cite>estimator.decision_function(X, y)</cite>.
See more information in the <span class="xref std std-ref">User guide</span>;</p></li>
<li><p>In the multiclass case, it corresponds to an array of shape
<cite>(n_samples, n_classes)</cite> of probability estimates provided by the
<cite>predict_proba</cite> method. The probability estimates <strong>must</strong>
sum to 1 across the possible classes. In addition, the order of the
class scores must correspond to the order of <code class="docutils literal notranslate"><span class="pre">labels</span></code>,
if provided, or else to the numerical or lexicographical order of
the labels in <code class="docutils literal notranslate"><span class="pre">y_true</span></code>. See more information in the
<span class="xref std std-ref">User guide</span>;</p></li>
<li><p>In the multilabel case, it corresponds to an array of shape
<cite>(n_samples, n_classes)</cite>. Probability estimates are provided by the
<cite>predict_proba</cite> method and the non-thresholded decision values by
the <cite>decision_function</cite> method. The probability estimates correspond
to the <strong>probability of the class with the greater label for each
output</strong> of the classifier. See more information in the
<span class="xref std std-ref">User guide</span>.</p></li>
</ul>
</dd>
<dt><strong>average</strong><span class="classifier">{‘micro’, ‘macro’, ‘samples’, ‘weighted’} or None,             default=’macro’</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the scores for each class are returned. Otherwise,
this determines the type of averaging performed on the data:
Note: multiclass ROC AUC currently only handles the ‘macro’ and
‘weighted’ averages.</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">'micro'</span></code>:</dt><dd><p>Calculate metrics globally by considering each element of the label
indicator matrix as a label.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">'macro'</span></code>:</dt><dd><p>Calculate metrics for each label, and find their unweighted
mean.  This does not take label imbalance into account.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">'weighted'</span></code>:</dt><dd><p>Calculate metrics for each label, and find their average, weighted
by support (the number of true instances for each label).</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">'samples'</span></code>:</dt><dd><p>Calculate metrics for each instance, and find their average.</p>
</dd>
</dl>
<p>Will be ignored when <code class="docutils literal notranslate"><span class="pre">y_true</span></code> is binary.</p>
</dd>
<dt><strong>sample_weight</strong><span class="classifier">array-like of shape (n_samples,), default=None</span></dt><dd><p>Sample weights.</p>
</dd>
<dt><strong>max_fpr</strong><span class="classifier">float &gt; 0 and &lt;= 1, default=None</span></dt><dd><p>If not <code class="docutils literal notranslate"><span class="pre">None</span></code>, the standardized partial AUC <a class="reference internal" href="#r16c5110711a3-2" id="id12">[2]</a> over the range
[0, max_fpr] is returned. For the multiclass case, <code class="docutils literal notranslate"><span class="pre">max_fpr</span></code>,
should be either equal to <code class="docutils literal notranslate"><span class="pre">None</span></code> or <code class="docutils literal notranslate"><span class="pre">1.0</span></code> as AUC ROC partial
computation currently is not supported for multiclass.</p>
</dd>
<dt><strong>multi_class</strong><span class="classifier">{‘raise’, ‘ovr’, ‘ovo’}, default=’raise’</span></dt><dd><p>Only used for multiclass targets. Determines the type of configuration
to use. The default value raises an error, so either
<code class="docutils literal notranslate"><span class="pre">'ovr'</span></code> or <code class="docutils literal notranslate"><span class="pre">'ovo'</span></code> must be passed explicitly.</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">'ovr'</span></code>:</dt><dd><p>Stands for One-vs-rest. Computes the AUC of each class
against the rest <a class="reference internal" href="#r16c5110711a3-3" id="id13">[3]</a> <a class="reference internal" href="#r16c5110711a3-4" id="id14">[4]</a>. This
treats the multiclass case in the same way as the multilabel case.
Sensitive to class imbalance even when <code class="docutils literal notranslate"><span class="pre">average</span> <span class="pre">==</span> <span class="pre">'macro'</span></code>,
because class imbalance affects the composition of each of the
‘rest’ groupings.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">'ovo'</span></code>:</dt><dd><p>Stands for One-vs-one. Computes the average AUC of all
possible pairwise combinations of classes <a class="reference internal" href="#r16c5110711a3-5" id="id15">[5]</a>.
Insensitive to class imbalance when
<code class="docutils literal notranslate"><span class="pre">average</span> <span class="pre">==</span> <span class="pre">'macro'</span></code>.</p>
</dd>
</dl>
</dd>
<dt><strong>labels</strong><span class="classifier">array-like of shape (n_classes,), default=None</span></dt><dd><p>Only used for multiclass targets. List of labels that index the
classes in <code class="docutils literal notranslate"><span class="pre">y_score</span></code>. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the numerical or lexicographical
order of the labels in <code class="docutils literal notranslate"><span class="pre">y_true</span></code> is used.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>auc</strong><span class="classifier">float</span></dt><dd></dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.average_precision_score" title="nlp_uncertainty_zoo.utils.uncertainty_eval.average_precision_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">average_precision_score</span></code></a></dt><dd><p>Area under the precision-recall curve.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">roc_curve</span></code></dt><dd><p>Compute Receiver operating characteristic (ROC) curve.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_roc_curve</span></code></dt><dd><p>Plot Receiver operating characteristic (ROC) curve.</p>
</dd>
</dl>
</div>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r16c5110711a3-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic">Wikipedia entry for the Receiver operating characteristic</a></p>
</div>
<div class="citation" id="r16c5110711a3-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id12">2</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://www.ncbi.nlm.nih.gov/pubmed/2668680">Analyzing a portion of the ROC curve. McClish, 1989</a></p>
</div>
<div class="citation" id="r16c5110711a3-3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id13">3</a><span class="fn-bracket">]</span></span>
<p>Provost, F., Domingos, P. (2000). Well-trained PETs: Improving
probability estimation trees (Section 6.2), CeDER Working Paper
#IS-00-04, Stern School of Business, New York University.</p>
</div>
<div class="citation" id="r16c5110711a3-4" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id14">4</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S016786550500303X">Fawcett, T. (2006). An introduction to ROC analysis. Pattern
Recognition Letters, 27(8), 861-874.</a></p>
</div>
<div class="citation" id="r16c5110711a3-5" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id15">5</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="http://link.springer.com/article/10.1023/A:1010920819831">Hand, D.J., Till, R.J. (2001). A Simple Generalisation of the Area
Under the ROC Curve for Multiple Class Classification Problems.
Machine Learning, 45(2), 171-186.</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<p>Binary case:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s2">&quot;liblinear&quot;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="go">0.99...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="go">0.99...</span>
</pre></div>
</div>
<p>Multiclass case:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s2">&quot;liblinear&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;ovr&#39;</span><span class="p">)</span>
<span class="go">0.99...</span>
</pre></div>
</div>
<p>Multilabel case:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_multilabel_classification</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.multioutput</span> <span class="kn">import</span> <span class="n">MultiOutputClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_multilabel_classification</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">MultiOutputClassifier</span><span class="p">(</span><span class="n">clf</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># get a list of n_output containing probability arrays of shape</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># (n_samples, n_classes)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># extract the positive columns for each output</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">([</span><span class="n">pred</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">y_pred</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="go">array([0.82..., 0.86..., 0.94..., 0.85... , 0.94...])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">RidgeClassifierCV</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">RidgeClassifierCV</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="go">array([0.81..., 0.84... , 0.93..., 0.87..., 0.94...])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nlp_uncertainty_zoo.utils.uncertainty_eval.sce">
<span class="sig-prename descclassname"><span class="pre">nlp_uncertainty_zoo.utils.uncertainty_eval.</span></span><span class="sig-name descname"><span class="pre">sce</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_bins</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.sce" title="Permalink to this definition">¶</a></dt>
<dd><p>Measure the Static Calibration Error (SCE) by [2], an extension to the Expected Calibration Error to multiple
classes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>y_true: np.array</strong></dt><dd><p>True labels for each input.</p>
</dd>
<dt><strong>y_pred: np.array</strong></dt><dd><p>Categorical probability distribution for each input.</p>
</dd>
<dt><strong>num_bins: int</strong></dt><dd><p>Number of bins. Default is 10.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>float</dt><dd><p>Static Calibration Error.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</section>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2022, Dennis Ulmer.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.3.0.<br/>
    </p>
  </div>
</footer>
  </body>
</html>