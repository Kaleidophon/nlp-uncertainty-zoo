<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Uncertainty Eval &#8212; nlp-uncertainty-zoo 0.9.2 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/bootstrap-sphinx.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Task Eval" href="nlp_uncertainty_zoo.utils.task_eval.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="_static/js/jquery-1.12.4.min.js"></script>
<script type="text/javascript" src="_static/js/jquery-fix.js"></script>
<script type="text/javascript" src="_static/bootstrap-3.4.1/js/bootstrap.min.js"></script>
<script type="text/javascript" src="_static/bootstrap-sphinx.js"></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html">
          nlp-uncertainty-zoo</a>
        <span class="navbar-text navbar-version pull-left"><b>0.9.2</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.html">nlp_uncertainty_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.html">Model package</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.bayesian_lstm.html">Bayesian LSTM</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.bayesian_lstm.html#bayesian-lstm-module-documentation">Bayesian LSTM Module Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.bert.html">BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.bert.html#module-nlp_uncertainty_zoo.models.bert">BERT Module Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.ddu_transformer.html">DDU Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.ddu_transformer.html#module-nlp_uncertainty_zoo.models.ddu_transformer">DDU Transformer Module Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.dpp_transformer.html">DPP Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.dpp_transformer.html#module-nlp_uncertainty_zoo.models.dpp_transformer">DPP Transformer Module Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.lstm.html">LSTM</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.lstm.html#module-nlp_uncertainty_zoo.models.lstm">LSTM Module Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.lstm_ensemble.html">LSTM Ensemble</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.lstm_ensemble.html#module-nlp_uncertainty_zoo.models.lstm_ensemble">LSTM Ensemble Module Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.model.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.model.html#the-module-class">The <cite>Module</cite> class</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.model.html#the-model-class">The <cite>Model</cite> class</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.model.html#module-nlp_uncertainty_zoo.models.model">Models Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.sngp_transformer.html">SNGP Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.sngp_transformer.html#module-nlp_uncertainty_zoo.models.sngp_transformer">SNGP Transformer Module Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.spectral.html">Spectral</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.spectral.html#module-nlp_uncertainty_zoo.models.spectral">Spectral Module Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.st_tau_lstm.html">ST-tau LSTM</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.st_tau_lstm.html#module-nlp_uncertainty_zoo.models.st_tau_lstm">ST-tau LSTM Module Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.transformer.html">Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.transformer.html#module-nlp_uncertainty_zoo.models.transformer">Transformer Module Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.st_tau_lstm.html">ST-tau LSTM</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.st_tau_lstm.html#module-nlp_uncertainty_zoo.models.st_tau_lstm">ST-tau LSTM Module Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.transformer.html">Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.transformer.html#module-nlp_uncertainty_zoo.models.transformer">Transformer Module Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.variational_lstm.html">Variational LSTM</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.variational_lstm.html#module-nlp_uncertainty_zoo.models.variational_lstm">Variational LSTM Module Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.variational_transformer.html">Variational Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.models.variational_transformer.html#variational-transformer-module-documentation">Variational Transformer Module Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.utils.html">Utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.utils.custom_types.html">Custom Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.utils.custom_types.html#module-nlp_uncertainty_zoo.utils.custom_types">Custom Types Module Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.utils.data.html">Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.utils.data.html#module-nlp_uncertainty_zoo.utils.data">Data Module Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.utils.metrics.html">Uncertainty metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.utils.metrics.html#module-nlp_uncertainty_zoo.utils.metrics">Metric Module Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.utils.samplers.html">Samplers</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.utils.samplers.html#module-nlp_uncertainty_zoo.utils.samplers">Samplers Module Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.utils.task_eval.html">Task Eval</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp_uncertainty_zoo.utils.task_eval.html#module-nlp_uncertainty_zoo.utils.task_eval">Task Eval Module Documentation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Uncertainty Eval</a></li>
<li class="toctree-l1"><a class="reference internal" href="#module-nlp_uncertainty_zoo.utils.uncertainty_eval">Uncertainty Eval Module Documentation</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Uncertainty Eval</a></li>
<li><a class="reference internal" href="#module-nlp_uncertainty_zoo.utils.uncertainty_eval">Uncertainty Eval Module Documentation</a><ul>
<li><a class="reference internal" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.ace"><code class="docutils literal notranslate"><span class="pre">ace()</span></code></a></li>
<li><a class="reference internal" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.aupr"><code class="docutils literal notranslate"><span class="pre">aupr()</span></code></a></li>
<li><a class="reference internal" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.auroc"><code class="docutils literal notranslate"><span class="pre">auroc()</span></code></a></li>
<li><a class="reference internal" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.coverage_percentage"><code class="docutils literal notranslate"><span class="pre">coverage_percentage()</span></code></a></li>
<li><a class="reference internal" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.coverage_width"><code class="docutils literal notranslate"><span class="pre">coverage_width()</span></code></a></li>
<li><a class="reference internal" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.ece"><code class="docutils literal notranslate"><span class="pre">ece()</span></code></a></li>
<li><a class="reference internal" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.kendalls_tau"><code class="docutils literal notranslate"><span class="pre">kendalls_tau()</span></code></a></li>
<li><a class="reference internal" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.sce"><code class="docutils literal notranslate"><span class="pre">sce()</span></code></a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
  <li>
    <a href="nlp_uncertainty_zoo.utils.task_eval.html" title="Previous Chapter: Task Eval"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; Task Eval</span>
    </a>
  </li>
              
            
            
            
            
              <li class="hidden-sm">
<div id="sourcelink">
  <a href="_sources/nlp_uncertainty_zoo.utils.uncertainty_eval.rst.txt"
     rel="nofollow">Source</a>
</div></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <section id="uncertainty-eval">
<h1>Uncertainty Eval<a class="headerlink" href="#uncertainty-eval" title="Permalink to this heading">¶</a></h1>
<p>Calibration and the quality of uncertainty estimates can be tricky to evaluate, since there are no gold labels like for a classification tasks.
For that reason, this module contains methods for exactly this purpose.</p>
<p>For calibration, the module implements the expected calibration error <a class="reference external" href="https://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/download/9667/9958">(Naeini et al., 2015)</a>, as well as the static calibration error and
the adaptive calibration error by <a class="reference external" href="https://openaccess.thecvf.com/content_CVPRW_2019/papers/Uncertainty%20and%20Robustness%20in%20Deep%20Visual%20Learning/Nixon_Measuring_Calibration_in_Deep_Learning_CVPRW_2019_paper.pdf">Nixon et al. (2019)</a>, where the former is an extension to multiple classes, and the latter uses ranges instead of bins,
making sure that every range contains the same number of points.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>In <a class="reference external" href="https://arxiv.org/pdf/2210.15452.pdf">Ulmer et al. (2022)</a>, we found that the SCE is not very informative for a relatively large number of classes (&gt; 5).</p>
</div>
<p>Furthermore, we implement the evaluation of prediction sets by <a class="reference external" href="http://arxiv.org/abs/2010.03039">Kompa et al. (2020)</a>: We determine the average width of prediction sets to reach 1 - alpha probability mass (<a class="reference internal" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.coverage_width" title="nlp_uncertainty_zoo.utils.uncertainty_eval.coverage_width"><code class="xref py py-func docutils literal notranslate"><span class="pre">nlp_uncertainty_zoo.utils.uncertainty_eval.coverage_width()</span></code></a>),
and what percentage of prediction sets contain the correct class (<a class="reference internal" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.coverage_percentage" title="nlp_uncertainty_zoo.utils.uncertainty_eval.coverage_percentage"><code class="xref py py-func docutils literal notranslate"><span class="pre">nlp_uncertainty_zoo.utils.uncertainty_eval.coverage_percentage()</span></code></a>).</p>
<p>To measure the quality of general uncertainty estimates, we use the common evaluation method of defining a proxy OOD detection tasks,
where we quantify how well we can distinguish in- and out-of-distribution inputs based on uncertainty scores given by a model.
This is realized using the area under the receiver-operator-characteristic (<a class="reference internal" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.aupr" title="nlp_uncertainty_zoo.utils.uncertainty_eval.aupr"><code class="xref py py-func docutils literal notranslate"><span class="pre">nlp_uncertainty_zoo.utils.uncertainty_eval.aupr()</span></code></a>) and
the area under precision-recall curve (<a class="reference internal" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.auroc" title="nlp_uncertainty_zoo.utils.uncertainty_eval.auroc"><code class="xref py py-func docutils literal notranslate"><span class="pre">nlp_uncertainty_zoo.utils.uncertainty_eval.auroc()</span></code></a>).</p>
<p>New in <a class="reference external" href="https://arxiv.org/pdf/2210.15452.pdf">Ulmer et al. (2022)</a>, it is also evaluated how indicative the uncertainty score is with the potential loss of a model.
For this reason, this module also implements the Kendall’s tau correlation coefficient (<a class="reference internal" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.kendalls_tau" title="nlp_uncertainty_zoo.utils.uncertainty_eval.kendalls_tau"><code class="xref py py-func docutils literal notranslate"><span class="pre">nlp_uncertainty_zoo.utils.uncertainty_eval.kendalls_tau()</span></code></a>).</p>
</section>
<section id="module-nlp_uncertainty_zoo.utils.uncertainty_eval">
<span id="uncertainty-eval-module-documentation"></span><h1>Uncertainty Eval Module Documentation<a class="headerlink" href="#module-nlp_uncertainty_zoo.utils.uncertainty_eval" title="Permalink to this heading">¶</a></h1>
<p>Module to implement different metrics the quality of uncertainty metrics.</p>
<dl class="py function">
<dt class="sig sig-object py" id="nlp_uncertainty_zoo.utils.uncertainty_eval.ace">
<span class="sig-prename descclassname"><span class="pre">nlp_uncertainty_zoo.utils.uncertainty_eval.</span></span><span class="sig-name descname"><span class="pre">ace</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_ranges</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.ace" title="Permalink to this definition">¶</a></dt>
<dd><blockquote>
<div><p>Measure the Adaptive Calibration Error (ACE) by [2], an version of the static calibration error that uses ranges
instead of bins. Every range contains the same number of predictions.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>y_true: np.array</strong></dt><dd><p>True labels for each input.</p>
</dd>
<dt><strong>y_pred: np.array</strong></dt><dd><p>Categorical probability distribution for each input.</p>
</dd>
<dt><strong>num_ranges: int</strong></dt><dd><p>Number of ranges. Default is 10.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>float</dt><dd><p>Adaptive Calibration Error.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nlp_uncertainty_zoo.utils.uncertainty_eval.aupr">
<span class="sig-prename descclassname"><span class="pre">nlp_uncertainty_zoo.utils.uncertainty_eval.</span></span><span class="sig-name descname"><span class="pre">aupr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">array</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.aupr" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the area under the precision-recall curve for a pseudo binary classification task, where in- and
out-of-distribution samples correspond to two different classes, which are differentiated using uncertainty scores.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>y_true: np.array</strong></dt><dd><p>True labels, where 1 corresponds to in- and 0 to out-of-distribution.</p>
</dd>
<dt><strong>y_pred: np.array</strong></dt><dd><p>Uncertainty scores as predictions to distinguish the two classes.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>float</dt><dd><p>Area under the precision-recall curve.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nlp_uncertainty_zoo.utils.uncertainty_eval.auroc">
<span class="sig-prename descclassname"><span class="pre">nlp_uncertainty_zoo.utils.uncertainty_eval.</span></span><span class="sig-name descname"><span class="pre">auroc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">array</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.auroc" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the area under the receiver-operator characteristic for a pseudo binary classification task, where in- and
out-of-distribution samples correspond to two different classes, which are differentiated using uncertainty scores.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>y_true: np.array</strong></dt><dd><p>True labels, where 1 corresponds to in- and 0 to out-of-distribution.</p>
</dd>
<dt><strong>y_pred: np.array</strong></dt><dd><p>Uncertainty scores as predictions to distinguish the two classes.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>float</dt><dd><p>Area under the receiver-operator characteristic.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nlp_uncertainty_zoo.utils.uncertainty_eval.coverage_percentage">
<span class="sig-prename descclassname"><span class="pre">nlp_uncertainty_zoo.utils.uncertainty_eval.</span></span><span class="sig-name descname"><span class="pre">coverage_percentage</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.05</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.coverage_percentage" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the percentage of times the true prediction was contained in the 1 - alpha prediction set. Based on the work
by [3].</p>
<p>[3] Kompa, Benjamin, Jasper Snoek, and Andrew L. Beam. “Empirical frequentist coverage of deep learning uncertainty
quantification procedures.” Entropy 23.12 (2021): 1608.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>y_true: np.array</strong></dt><dd><p>True labels for each input.</p>
</dd>
<dt><strong>y_pred: np.array</strong></dt><dd><p>Categorical probability distribution for each input.</p>
</dd>
<dt><strong>alpha: float</strong></dt><dd><p>Probability mass threshold.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>float</dt><dd><p>Coverage percentage.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nlp_uncertainty_zoo.utils.uncertainty_eval.coverage_width">
<span class="sig-prename descclassname"><span class="pre">nlp_uncertainty_zoo.utils.uncertainty_eval.</span></span><span class="sig-name descname"><span class="pre">coverage_width</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_pred</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-08</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.coverage_width" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the width of the 1 - alpha prediction set. Based on the work by [3].</p>
<p>[3] Kompa, Benjamin, Jasper Snoek, and Andrew L. Beam. “Empirical frequentist coverage of deep learning uncertainty
quantification procedures.” Entropy 23.12 (2021): 1608.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>y_pred: np.array</strong></dt><dd><p>Categorical probability distribution for each input.</p>
</dd>
<dt><strong>alpha: float</strong></dt><dd><p>Probability mass threshold.</p>
</dd>
<dt><strong>eps: float</strong></dt><dd><p>Small number to avoid floating point precision problems.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>float</dt><dd><p>Average prediction set width.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nlp_uncertainty_zoo.utils.uncertainty_eval.ece">
<span class="sig-prename descclassname"><span class="pre">nlp_uncertainty_zoo.utils.uncertainty_eval.</span></span><span class="sig-name descname"><span class="pre">ece</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_bins</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.ece" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the Expected Calibration Error: for each bin, the absolute difference between
the mean fraction of positives and the average predicted probability is taken. The ECE is
the weighed mean of these differences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>y: np.ndarray</strong></dt><dd><p>The true labels.</p>
</dd>
<dt><strong>y_pred: np.ndarray</strong></dt><dd><p>The predicted probabilities</p>
</dd>
<dt><strong>n_bins: int</strong></dt><dd><p>The number of bins to use.</p>
</dd>
<dt><strong>Returns</strong></dt><dd></dd>
<dt><strong>——-</strong></dt><dd></dd>
<dt><strong>ece: float</strong></dt><dd><p>The expected calibration error.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nlp_uncertainty_zoo.utils.uncertainty_eval.kendalls_tau">
<span class="sig-prename descclassname"><span class="pre">nlp_uncertainty_zoo.utils.uncertainty_eval.</span></span><span class="sig-name descname"><span class="pre">kendalls_tau</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">losses</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">uncertainties</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">array</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.kendalls_tau" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute Kendall’s tau for a list of losses and uncertainties for a set of inputs. If the two lists are concordant,
i.e. the points with the highest uncertainty incur the highest loss, Kendall’s tau is 1. If they are completely
discordant, it is -1.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>losses: np.array</strong></dt><dd><p>List of losses for a set of points.</p>
</dd>
<dt><strong>uncertainties: np.array</strong></dt><dd><p>List of uncertainty for a set of points.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>float</dt><dd><p>Kendall’s tau, between -1 and 1.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nlp_uncertainty_zoo.utils.uncertainty_eval.sce">
<span class="sig-prename descclassname"><span class="pre">nlp_uncertainty_zoo.utils.uncertainty_eval.</span></span><span class="sig-name descname"><span class="pre">sce</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_bins</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#nlp_uncertainty_zoo.utils.uncertainty_eval.sce" title="Permalink to this definition">¶</a></dt>
<dd><p>Measure the Static Calibration Error (SCE) by [2], an extension to the Expected Calibration Error to multiple
classes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>y_true: np.array</strong></dt><dd><p>True labels for each input.</p>
</dd>
<dt><strong>y_pred: np.array</strong></dt><dd><p>Categorical probability distribution for each input.</p>
</dd>
<dt><strong>num_bins: int</strong></dt><dd><p>Number of bins. Default is 10.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>float</dt><dd><p>Static Calibration Error.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</section>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2022, Dennis Ulmer.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 6.1.3.<br/>
    </p>
  </div>
</footer>
  </body>
</html>